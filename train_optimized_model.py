#!/usr/bin/env python3
"""
ä¼˜åŒ–ç‰ˆæ¤ç‰©ç—…å®³è¯†åˆ«æ¨¡å‹è®­ç»ƒè„šæœ¬
æ•´åˆæ‰€æœ‰è®­ç»ƒç­–ç•¥ä¼˜åŒ–å’Œæ€§èƒ½è°ƒä¼˜åŠŸèƒ½
"""

import os
import sys
import time
import json
import argparse
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

try:
    import torch
    import torch.nn as nn
    from torch.utils.data import DataLoader, Dataset
    import numpy as np
    from tqdm import tqdm
    DEPENDENCIES_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸  ç¼ºå°‘ä¾èµ–: {e}")
    DEPENDENCIES_AVAILABLE = False

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from src.model_architecture import create_plant_disease_model, ModelFactory
from src.model_trainer import ModelTrainer, TrainingConfig, create_default_config
from src.model_evaluator import ModelEvaluator, create_evaluator
from src.image_preprocessing import PlantDiseasePreprocessor, PreprocessingMode
from src.training_strategies import (
    ClassBalanceStrategy, FocalLoss, ProgressiveTrainer, 
    GradientAccumulator, create_balanced_dataloader
)
from src.model_optimization import (
    HyperparameterOptimizer, ModelEnsemble, InferenceOptimizer,
    PerformanceTuner, create_hyperparameter_optimizer
)
from src.dataset_manager import DatasetManager

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('optimized_training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class OptimizedTrainingManager:
    """ä¼˜åŒ–è®­ç»ƒç®¡ç†å™¨"""
    
    def __init__(self, config_path: Optional[str] = None):
        """
        åˆå§‹åŒ–ä¼˜åŒ–è®­ç»ƒç®¡ç†å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        if not DEPENDENCIES_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£…å¿…è¦ä¾èµ–")
        
        # åŠ è½½é…ç½®
        self.config = self._load_config(config_path)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.dataset_manager = DatasetManager()
        self.trainer = None
        self.evaluator = None
        self.performance_tuner = PerformanceTuner()
        
        # æ•°æ®é›†ä¿¡æ¯
        self.train_dataset = None
        self.val_dataset = None
        self.test_dataset = None
        self.class_names = []
        self.class_labels = []
        
        logger.info("ä¼˜åŒ–è®­ç»ƒç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_config(self, config_path: Optional[str]) -> TrainingConfig:
        """åŠ è½½è®­ç»ƒé…ç½®"""
        if config_path and os.path.exists(config_path):
            with open(config_path, 'r') as f:
                config_dict = json.load(f)
            
            # åˆ›å»ºé…ç½®å¯¹è±¡
            config = TrainingConfig()
            for key, value in config_dict.items():
                if hasattr(config, key):
                    setattr(config, key, value)
            
            logger.info(f"é…ç½®å·²ä»æ–‡ä»¶åŠ è½½: {config_path}")
        else:
            # ä½¿ç”¨GPUä¼˜åŒ–é…ç½®
            config = create_default_config(
                num_epochs=30,
                batch_size=8,  # é€‚åˆ6GBæ˜¾å­˜
                learning_rate=0.001,
                model_name='efficientnet-b4',
                pretrained=True,
                device='cuda' if torch.cuda.is_available() else 'cpu',
                mixed_precision=True,
                early_stopping=True,
                patience=10,
                save_dir='checkpoints/optimized_plant_disease_model'
            )
            logger.info("ä½¿ç”¨é»˜è®¤GPUä¼˜åŒ–é…ç½®")
        
        return config
    
    def prepare_datasets_with_balance(self) -> Dict[str, Any]:
        """å‡†å¤‡å¸¦ç±»åˆ«å¹³è¡¡çš„æ•°æ®é›†"""
        logger.info("å¼€å§‹å‡†å¤‡å¹³è¡¡æ•°æ®é›†...")
        
        # ä½¿ç”¨è™šæ‹Ÿæ•°æ®é›†è¿›è¡Œè®­ç»ƒæ¼”ç¤º
        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šåŠ è½½çœŸå®çš„PlantVillageæ•°æ®é›†
        
        # åˆ›å»ºè™šæ‹Ÿçš„æ¤ç‰©ç—…å®³æ•°æ®
        num_samples = 2000  # æ€»æ ·æœ¬æ•°
        num_classes = 38    # æ¤ç‰©ç—…å®³ç±»åˆ«æ•°
        
        # æ¨¡æ‹Ÿç±»åˆ«ä¸å¹³è¡¡çš„æ•°æ®åˆ†å¸ƒ
        np.random.seed(42)
        class_counts = np.random.randint(20, 100, num_classes)  # æ¯ä¸ªç±»åˆ«20-100ä¸ªæ ·æœ¬
        
        # ç”Ÿæˆè™šæ‹Ÿå›¾åƒæ•°æ®å’Œæ ‡ç­¾
        all_images = []
        all_labels = []
        
        for class_id in range(num_classes):
            count = class_counts[class_id]
            # ç”Ÿæˆè¯¥ç±»åˆ«çš„è™šæ‹Ÿå›¾åƒï¼ˆéšæœºå™ªå£°ï¼‰
            class_images = torch.randn(count, 3, 224, 224)
            class_labels = [class_id] * count
            
            all_images.append(class_images)
            all_labels.extend(class_labels)
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        all_images = torch.cat(all_images, dim=0)
        
        # åˆ›å»ºç±»åˆ«åç§°
        self.class_names = [f'æ¤ç‰©ç—…å®³_{i:02d}' for i in range(num_classes)]
        self.class_labels = all_labels
        
        # æ•°æ®é›†åˆ†å‰²ï¼ˆåˆ†å±‚é‡‡æ ·ï¼‰
        from sklearn.model_selection import train_test_split
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„ä»¥ä¾¿åˆ†å‰²
        images_np = all_images.numpy()
        labels_np = np.array(all_labels)
        
        train_images, temp_images, train_labels, temp_labels = train_test_split(
            images_np, labels_np, 
            test_size=0.3,
            stratify=labels_np,
            random_state=42
        )
        
        val_images, test_images, val_labels, test_labels = train_test_split(
            temp_images, temp_labels,
            test_size=0.5,
            stratify=temp_labels,
            random_state=42
        )
        
        # è½¬æ¢å›tensor
        train_images = torch.from_numpy(train_images)
        val_images = torch.from_numpy(val_images)
        test_images = torch.from_numpy(test_images)
        
        train_labels = torch.from_numpy(train_labels)
        val_labels = torch.from_numpy(val_labels)
        test_labels = torch.from_numpy(test_labels)
        
        # åˆ›å»ºæ•°æ®é›†å¯¹è±¡
        from torch.utils.data import TensorDataset
        
        self.train_dataset = TensorDataset(train_images, train_labels)
        self.val_dataset = TensorDataset(val_images, val_labels)
        self.test_dataset = TensorDataset(test_images, test_labels)
        
        # åˆ†æç±»åˆ«åˆ†å¸ƒ
        from collections import Counter
        train_distribution = Counter(train_labels.tolist())
        
        logger.info(f"è™šæ‹Ÿæ•°æ®é›†å‡†å¤‡å®Œæˆ:")
        logger.info(f"  è®­ç»ƒé›†: {len(train_labels):,} æ ·æœ¬")
        logger.info(f"  éªŒè¯é›†: {len(val_labels):,} æ ·æœ¬")
        logger.info(f"  æµ‹è¯•é›†: {len(test_labels):,} æ ·æœ¬")
        logger.info(f"  ç±»åˆ«åˆ†å¸ƒä¸å¹³è¡¡åº¦: {max(train_distribution.values()) / min(train_distribution.values()):.2f}")
        
        return {
            'total_samples': len(all_labels),
            'train_samples': len(train_labels),
            'val_samples': len(val_labels),
            'test_samples': len(test_labels),
            'num_classes': len(self.class_names),
            'class_names': self.class_names,
            'class_distribution': dict(train_distribution)
        }
    
    def create_balanced_dataloaders(self) -> Tuple[DataLoader, DataLoader, DataLoader]:
        """åˆ›å»ºå¹³è¡¡çš„æ•°æ®åŠ è½½å™¨"""
        logger.info("åˆ›å»ºå¹³è¡¡æ•°æ®åŠ è½½å™¨...")
        
        # åˆ›å»ºç±»åˆ«å¹³è¡¡ç­–ç•¥
        balance_strategy = ClassBalanceStrategy('weighted_sampling')
        
        # è·å–è®­ç»ƒé›†æ ‡ç­¾
        train_labels = [self.train_dataset[i][1].item() for i in range(len(self.train_dataset))]
        
        # åˆ›å»ºåŠ æƒé‡‡æ ·å™¨
        sampler = balance_strategy.create_weighted_sampler(
            train_labels, len(self.class_names)
        )
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader = DataLoader(
            self.train_dataset,
            batch_size=self.config.batch_size,
            sampler=sampler,
            num_workers=0,  # Windowså…¼å®¹æ€§
            pin_memory=True if torch.cuda.is_available() else False
        )
        
        val_loader = DataLoader(
            self.val_dataset,
            batch_size=self.config.batch_size,
            shuffle=False,
            num_workers=0,
            pin_memory=True if torch.cuda.is_available() else False
        )
        
        test_loader = DataLoader(
            self.test_dataset,
            batch_size=self.config.batch_size,
            shuffle=False,
            num_workers=0,
            pin_memory=True if torch.cuda.is_available() else False
        )
        
        logger.info("å¹³è¡¡æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ")
        return train_loader, val_loader, test_loader
    
    def setup_advanced_training(self) -> Dict[str, Any]:
        """è®¾ç½®é«˜çº§è®­ç»ƒç¯å¢ƒ"""
        logger.info("è®¾ç½®é«˜çº§è®­ç»ƒç¯å¢ƒ...")
        
        # æ›´æ–°é…ç½®ä¸­çš„ç±»åˆ«æ•°
        self.config.num_classes = len(self.class_names)
        
        # åˆ›å»ºè®­ç»ƒå™¨
        self.trainer = ModelTrainer(self.config)
        
        # è®¾ç½®æ¨¡å‹
        model = self.trainer.setup_model()
        
        # ä½¿ç”¨Focal Losså¤„ç†ç±»åˆ«ä¸å¹³è¡¡
        focal_loss = FocalLoss(alpha=1.0, gamma=2.0)
        self.trainer.criterion = focal_loss.to(self.trainer.device)
        
        # åˆ›å»ºè¯„ä¼°å™¨
        self.evaluator = create_evaluator(
            class_names=self.class_names,
            device=str(self.trainer.device)
        )
        
        # è®¾ç½®æ¸è¿›å¼è®­ç»ƒ
        progressive_trainer = ProgressiveTrainer(
            model, 
            self.performance_tuner.hyperopt.create_default_search_space()
        )
        
        # è·å–æ¨¡å‹ä¿¡æ¯
        model_info = ModelFactory.get_model_info(model)
        
        setup_info = {
            'model_info': model_info,
            'device': str(self.trainer.device),
            'loss_function': 'FocalLoss',
            'balance_strategy': 'WeightedSampling',
            'progressive_training': True
        }
        
        logger.info(f"é«˜çº§è®­ç»ƒç¯å¢ƒè®¾ç½®å®Œæˆ:")
        logger.info(f"  æ¨¡å‹: {model_info['model_type']}")
        logger.info(f"  å‚æ•°æ•°é‡: {model_info['total_parameters']:,}")
        logger.info(f"  è®¾å¤‡: {setup_info['device']}")
        logger.info(f"  æŸå¤±å‡½æ•°: {setup_info['loss_function']}")
        
        return setup_info
    
    def train_with_optimization(self, 
                              train_loader: DataLoader,
                              val_loader: DataLoader,
                              enable_hyperopt: bool = False) -> Dict[str, Any]:
        """æ‰§è¡Œä¼˜åŒ–è®­ç»ƒ"""
        logger.info("å¼€å§‹ä¼˜åŒ–è®­ç»ƒ...")
        
        if enable_hyperopt:
            # è¶…å‚æ•°ä¼˜åŒ–
            logger.info("æ‰§è¡Œè¶…å‚æ•°ä¼˜åŒ–...")
            hyperopt = create_hyperparameter_optimizer('random', max_trials=10)
            
            hyperopt_results = hyperopt.optimize(
                self.config, train_loader, val_loader
            )
            
            # ä½¿ç”¨æœ€ä½³å‚æ•°æ›´æ–°é…ç½®
            best_params = hyperopt_results['best_params']
            for key, value in best_params.items():
                setattr(self.config, key, value)
            
            # é‡æ–°åˆ›å»ºè®­ç»ƒå™¨
            self.trainer = ModelTrainer(self.config)
            model = self.trainer.setup_model()
            
            logger.info(f"ä½¿ç”¨ä¼˜åŒ–åçš„è¶…å‚æ•°: {best_params}")
        
        # æ‰§è¡Œè®­ç»ƒ
        training_results = self.trainer.train(train_loader, val_loader)
        
        logger.info(f"ä¼˜åŒ–è®­ç»ƒå®Œæˆ:")
        logger.info(f"  æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {training_results['best_val_acc']:.2f}%")
        logger.info(f"  æœ€ä½³è½®æ¬¡: {training_results['best_epoch']}")
        logger.info(f"  æ€»è®­ç»ƒæ—¶é—´: {training_results['total_time']:.2f}ç§’")
        
        return training_results
    
    def evaluate_with_optimization(self, test_loader: DataLoader) -> Dict[str, Any]:
        """æ‰§è¡Œä¼˜åŒ–è¯„ä¼°"""
        logger.info("å¼€å§‹ä¼˜åŒ–è¯„ä¼°...")
        
        # åŠ è½½æœ€ä½³æ¨¡å‹
        best_model_path = Path(self.config.save_dir) / 'best_model.pth'
        if best_model_path.exists():
            checkpoint = self.trainer.load_checkpoint('best_model.pth')
            logger.info("å·²åŠ è½½æœ€ä½³æ¨¡å‹æƒé‡")
        
        # æ¨ç†ä¼˜åŒ–
        example_input = next(iter(test_loader))[0][:1].to(self.trainer.device)
        
        inference_opt = InferenceOptimizer()
        optimization_results = inference_opt.compare_optimizations(
            self.trainer.model, example_input
        )
        
        # ä½¿ç”¨ä¼˜åŒ–åçš„æ¨¡å‹è¿›è¡Œè¯„ä¼°
        optimized_model = inference_opt.optimize_for_inference(
            self.trainer.model, example_input, 'basic'
        )
        
        # è¯„ä¼°æ¨¡å‹
        metrics, predictions = self.evaluator.evaluate_model(
            optimized_model,
            test_loader,
            return_predictions=True
        )
        
        # è·å–ç±»åˆ«æŒ‡æ ‡
        class_metrics = self.evaluator.get_class_metrics()
        
        # ä¿å­˜è¯„ä¼°æŠ¥å‘Š
        self.evaluator.save_evaluation_report(
            metrics,
            save_dir=self.config.save_dir,
            model_name='optimized_plant_disease_model'
        )
        
        evaluation_results = {
            'overall_metrics': {
                'accuracy': metrics.accuracy,
                'f1_macro': metrics.f1_macro,
                'f1_weighted': metrics.f1_weighted,
                'precision_macro': metrics.precision_macro,
                'recall_macro': metrics.recall_macro
            },
            'top_k_accuracy': metrics.top_k_accuracy,
            'inference_optimization': optimization_results,
            'class_metrics_summary': {
                'best_class': max(class_metrics, key=lambda x: x.f1_score),
                'worst_class': min(class_metrics, key=lambda x: x.f1_score),
                'avg_f1': np.mean([cm.f1_score for cm in class_metrics])
            }
        }
        
        logger.info(f"ä¼˜åŒ–è¯„ä¼°å®Œæˆ:")
        logger.info(f"  æµ‹è¯•å‡†ç¡®ç‡: {metrics.accuracy:.4f}")
        logger.info(f"  F1åˆ†æ•°(å®): {metrics.f1_macro:.4f}")
        logger.info(f"  æ¨ç†åŠ é€Ÿæ¯”: {optimization_results['speedup']['basic']:.2f}x")
        
        return evaluation_results
    
    def run_complete_optimized_training(self, enable_hyperopt: bool = False) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„ä¼˜åŒ–è®­ç»ƒæµç¨‹"""
        logger.info("=" * 80)
        logger.info("å¼€å§‹ä¼˜åŒ–ç‰ˆæ¤ç‰©ç—…å®³è¯†åˆ«æ¨¡å‹è®­ç»ƒ")
        logger.info("=" * 80)
        
        start_time = time.time()
        
        try:
            # 1. å‡†å¤‡å¹³è¡¡æ•°æ®é›†
            dataset_summary = self.prepare_datasets_with_balance()
            
            # 2. åˆ›å»ºå¹³è¡¡æ•°æ®åŠ è½½å™¨
            train_loader, val_loader, test_loader = self.create_balanced_dataloaders()
            
            # 3. è®¾ç½®é«˜çº§è®­ç»ƒç¯å¢ƒ
            setup_info = self.setup_advanced_training()
            
            # 4. æ‰§è¡Œä¼˜åŒ–è®­ç»ƒ
            training_results = self.train_with_optimization(
                train_loader, val_loader, enable_hyperopt
            )
            
            # 5. æ‰§è¡Œä¼˜åŒ–è¯„ä¼°
            evaluation_results = self.evaluate_with_optimization(test_loader)
            
            # 6. ä¿å­˜å®Œæ•´æŠ¥å‘Š
            complete_results = {
                'dataset_summary': dataset_summary,
                'setup_info': setup_info,
                'training_results': training_results,
                'evaluation_results': evaluation_results
            }
            
            self.performance_tuner.save_optimization_report(
                complete_results,
                str(Path(self.config.save_dir) / 'complete_optimization_report.json')
            )
            
            total_time = time.time() - start_time
            
            logger.info("=" * 80)
            logger.info("ä¼˜åŒ–è®­ç»ƒæµç¨‹å®Œæˆ")
            logger.info(f"æ€»è€—æ—¶: {total_time:.2f}ç§’")
            logger.info(f"æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {evaluation_results['overall_metrics']['accuracy']:.4f}")
            logger.info(f"æ¨ç†ä¼˜åŒ–åŠ é€Ÿ: {evaluation_results['inference_optimization']['speedup']['basic']:.2f}x")
            logger.info("=" * 80)
            
            return {
                'success': True,
                'total_time': total_time,
                'results': complete_results
            }
            
        except Exception as e:
            logger.error(f"ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            
            return {
                'success': False,
                'error': str(e),
                'total_time': time.time() - start_time
            }

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ä¼˜åŒ–ç‰ˆæ¤ç‰©ç—…å®³è¯†åˆ«æ¨¡å‹è®­ç»ƒ')
    parser.add_argument('--config', type=str, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--hyperopt', action='store_true', help='å¯ç”¨è¶…å‚æ•°ä¼˜åŒ–')
    parser.add_argument('--gpu-config', action='store_true', help='ä½¿ç”¨GPUä¼˜åŒ–é…ç½®')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥ä¾èµ–
    if not DEPENDENCIES_AVAILABLE:
        print("âŒ ç¼ºå°‘å¿…è¦ä¾èµ–ï¼Œè¯·è¿è¡Œ: pip install -r requirements.txt")
        return
    
    # æ£€æŸ¥GPU
    if torch.cuda.is_available():
        print(f"ğŸš€ æ£€æµ‹åˆ°GPU: {torch.cuda.get_device_name(0)}")
        print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    else:
        print("âš ï¸  æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
    
    # ä½¿ç”¨GPUé…ç½®
    config_path = args.config
    if args.gpu_config and not config_path:
        config_path = 'gpu_training_config.json'
        if not os.path.exists(config_path):
            print("âŒ GPUé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ: python check_gpu.py")
            return
    
    # åˆ›å»ºä¼˜åŒ–è®­ç»ƒç®¡ç†å™¨
    training_manager = OptimizedTrainingManager(config_path)
    
    # è¿è¡Œå®Œæ•´ä¼˜åŒ–è®­ç»ƒ
    results = training_manager.run_complete_optimized_training(
        enable_hyperopt=args.hyperopt
    )
    
    if results['success']:
        print("\nğŸ‰ ä¼˜åŒ–è®­ç»ƒæˆåŠŸå®Œæˆ!")
        final_results = results['results']['evaluation_results']['overall_metrics']
        print(f"ğŸ“Š æœ€ç»ˆå‡†ç¡®ç‡: {final_results['accuracy']:.4f}")
        print(f"ğŸ“Š F1åˆ†æ•°: {final_results['f1_macro']:.4f}")
        print(f"â±ï¸  æ€»è€—æ—¶: {results['total_time']:.2f}ç§’")
        
        # æ˜¾ç¤ºæ¨ç†ä¼˜åŒ–ç»“æœ
        inference_results = results['results']['evaluation_results']['inference_optimization']
        print(f"ğŸš€ æ¨ç†ä¼˜åŒ–:")
        print(f"   åŸå§‹é€Ÿåº¦: {inference_results['original']['avg_inference_time_ms']:.1f}ms")
        print(f"   ä¼˜åŒ–é€Ÿåº¦: {inference_results['basic_optimized']['avg_inference_time_ms']:.1f}ms")
        print(f"   åŠ é€Ÿæ¯”: {inference_results['speedup']['basic']:.2f}x")
    else:
        print(f"\nâŒ ä¼˜åŒ–è®­ç»ƒå¤±è´¥: {results['error']}")

if __name__ == "__main__":
    main()