#!/usr/bin/env python3
"""
æ•°æ®è´¨é‡æ£€æŸ¥å·¥å…·
æ£€æŸ¥PlantVillageå’Œç™¾åº¦AI Studioæ•°æ®é›†çš„è´¨é‡é—®é¢˜
"""

import os
import sys
from pathlib import Path
import json
from collections import defaultdict, Counter
from typing import Dict, List, Tuple, Any
import time
import hashlib

try:
    from PIL import Image, ImageStat
    import numpy as np
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("âš ï¸  PIL/numpyæœªå®‰è£…ï¼Œæ— æ³•è¿›è¡Œæ·±åº¦è´¨é‡æ£€æŸ¥")
    print("   å®‰è£…: pip install Pillow numpy")

class DataQualityChecker:
    def __init__(self):
        self.issues = {
            'corrupted_images': [],
            'duplicate_images': [],
            'low_quality_images': [],
            'size_anomalies': [],
            'format_issues': [],
            'label_issues': []
        }
        
    def check_image_corruption(self, image_path: str) -> bool:
        """æ£€æŸ¥å›¾åƒæ˜¯å¦æŸå"""
        try:
            with Image.open(image_path) as img:
                img.verify()  # éªŒè¯å›¾åƒå®Œæ•´æ€§
            return True
        except Exception as e:
            self.issues['corrupted_images'].append({
                'path': image_path,
                'error': str(e)
            })
            return False
    
    def calculate_image_hash(self, image_path: str) -> str:
        """è®¡ç®—å›¾åƒå“ˆå¸Œå€¼ç”¨äºé‡å¤æ£€æµ‹"""
        try:
            with Image.open(image_path) as img:
                # è½¬æ¢ä¸ºRGBå¹¶ç¼©æ”¾åˆ°å°å°ºå¯¸è®¡ç®—å“ˆå¸Œ
                img = img.convert('RGB').resize((8, 8))
                img_array = np.array(img)
                return hashlib.md5(img_array.tobytes()).hexdigest()
        except:
            return None
    
    def check_image_quality(self, image_path: str) -> Dict[str, Any]:
        """æ£€æŸ¥å›¾åƒè´¨é‡"""
        try:
            with Image.open(image_path) as img:
                # åŸºæœ¬ä¿¡æ¯
                width, height = img.size
                mode = img.mode
                
                # è®¡ç®—å›¾åƒç»Ÿè®¡ä¿¡æ¯
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                
                stat = ImageStat.Stat(img)
                
                quality_info = {
                    'size': (width, height),
                    'mode': mode,
                    'mean_brightness': np.mean(stat.mean),
                    'std_brightness': np.mean(stat.stddev),
                    'file_size': os.path.getsize(image_path)
                }
                
                # è´¨é‡é—®é¢˜æ£€æµ‹
                issues = []
                
                # 1. å°ºå¯¸è¿‡å°
                if width < 100 or height < 100:
                    issues.append('too_small')
                
                # 2. å°ºå¯¸å¼‚å¸¸å¤§
                if width > 5000 or height > 5000:
                    issues.append('too_large')
                
                # 3. é•¿å®½æ¯”å¼‚å¸¸
                aspect_ratio = max(width, height) / min(width, height)
                if aspect_ratio > 5:
                    issues.append('extreme_aspect_ratio')
                
                # 4. äº®åº¦å¼‚å¸¸
                if quality_info['mean_brightness'] < 20:
                    issues.append('too_dark')
                elif quality_info['mean_brightness'] > 235:
                    issues.append('too_bright')
                
                # 5. å¯¹æ¯”åº¦è¿‡ä½
                if quality_info['std_brightness'] < 10:
                    issues.append('low_contrast')
                
                # 6. æ–‡ä»¶å¤§å°å¼‚å¸¸
                if quality_info['file_size'] < 1000:  # å°äº1KB
                    issues.append('file_too_small')
                elif quality_info['file_size'] > 10 * 1024 * 1024:  # å¤§äº10MB
                    issues.append('file_too_large')
                
                if issues:
                    self.issues['low_quality_images'].append({
                        'path': image_path,
                        'issues': issues,
                        'info': quality_info
                    })
                
                return quality_info
                
        except Exception as e:
            self.issues['format_issues'].append({
                'path': image_path,
                'error': str(e)
            })
            return None
    
    def check_dataset_balance(self, class_distribution: Dict[str, int]) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®é›†ç±»åˆ«å¹³è¡¡æ€§"""
        if not class_distribution:
            return {'balanced': True, 'issues': []}
        
        counts = list(class_distribution.values())
        mean_count = np.mean(counts)
        std_count = np.std(counts)
        min_count = min(counts)
        max_count = max(counts)
        
        issues = []
        
        # æ£€æŸ¥ç±»åˆ«ä¸å¹³è¡¡
        imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')
        if imbalance_ratio > 10:
            issues.append(f'severe_imbalance_ratio_{imbalance_ratio:.1f}')
        elif imbalance_ratio > 5:
            issues.append(f'moderate_imbalance_ratio_{imbalance_ratio:.1f}')
        
        # æ£€æŸ¥æ ·æœ¬è¿‡å°‘çš„ç±»åˆ«
        few_sample_classes = [cls for cls, count in class_distribution.items() if count < 100]
        if few_sample_classes:
            issues.append(f'few_samples_{len(few_sample_classes)}_classes')
        
        return {
            'balanced': len(issues) == 0,
            'issues': issues,
            'stats': {
                'mean': mean_count,
                'std': std_count,
                'min': min_count,
                'max': max_count,
                'imbalance_ratio': imbalance_ratio
            },
            'few_sample_classes': few_sample_classes
        }
    
    def check_plantvillage_dataset(self, base_path: str, max_samples: int = 1000) -> Dict[str, Any]:
        """æ£€æŸ¥PlantVillageæ•°æ®é›†è´¨é‡"""
        print("\nğŸ” æ£€æŸ¥PlantVillageæ•°æ®é›†è´¨é‡...")
        
        color_path = os.path.join(base_path, "1.å›¾åƒæ•°æ®ï¼ˆç—…è™«å®³è¯†åˆ«æ ¸å¿ƒï¼‰", 
                                 "plantvillage dataset", "color")
        
        if not os.path.exists(color_path):
            return {'status': 'not_found', 'message': f'è·¯å¾„ä¸å­˜åœ¨: {color_path}'}
        
        # æ”¶é›†æ‰€æœ‰å›¾åƒæ–‡ä»¶å’Œç±»åˆ«ä¿¡æ¯
        image_files = []
        class_distribution = defaultdict(int)
        
        for root, dirs, files in os.walk(color_path):
            class_name = os.path.basename(root)
            if class_name != 'color':  # è·³è¿‡æ ¹ç›®å½•
                for file in files:
                    if file.lower().endswith(('.jpg', '.jpeg', '.png')):
                        image_path = os.path.join(root, file)
                        image_files.append((image_path, class_name))
                        class_distribution[class_name] += 1
        
        print(f"   æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒï¼Œ{len(class_distribution)} ä¸ªç±»åˆ«")
        
        # é‡‡æ ·æ£€æŸ¥ï¼ˆé¿å…æ£€æŸ¥æ—¶é—´è¿‡é•¿ï¼‰
        if len(image_files) > max_samples:
            import random
            sampled_files = random.sample(image_files, max_samples)
            print(f"   é‡‡æ · {max_samples} å¼ å›¾åƒè¿›è¡Œè´¨é‡æ£€æŸ¥")
        else:
            sampled_files = image_files
        
        # è´¨é‡æ£€æŸ¥
        image_hashes = {}
        quality_stats = []
        
        for i, (image_path, class_name) in enumerate(sampled_files):
            if i % 100 == 0:
                print(f"   æ£€æŸ¥è¿›åº¦: {i}/{len(sampled_files)}")
            
            # æ£€æŸ¥æŸå
            if not self.check_image_corruption(image_path):
                continue
            
            # æ£€æŸ¥é‡å¤
            img_hash = self.calculate_image_hash(image_path)
            if img_hash:
                if img_hash in image_hashes:
                    self.issues['duplicate_images'].append({
                        'original': image_hashes[img_hash],
                        'duplicate': image_path
                    })
                else:
                    image_hashes[img_hash] = image_path
            
            # æ£€æŸ¥è´¨é‡
            quality_info = self.check_image_quality(image_path)
            if quality_info:
                quality_stats.append(quality_info)
        
        # æ£€æŸ¥ç±»åˆ«å¹³è¡¡
        balance_info = self.check_dataset_balance(dict(class_distribution))
        
        return {
            'status': 'checked',
            'total_images': len(image_files),
            'sampled_images': len(sampled_files),
            'class_distribution': dict(class_distribution),
            'balance_info': balance_info,
            'quality_stats': {
                'mean_size': np.mean([q['size'][0] * q['size'][1] for q in quality_stats]) if quality_stats else 0,
                'mean_brightness': np.mean([q['mean_brightness'] for q in quality_stats]) if quality_stats else 0,
                'mean_file_size': np.mean([q['file_size'] for q in quality_stats]) if quality_stats else 0
            }
        }
    
    def check_baidu_dataset(self, base_path: str, max_samples: int = 500) -> Dict[str, Any]:
        """æ£€æŸ¥ç™¾åº¦AI Studioæ•°æ®é›†è´¨é‡"""
        print("\nğŸ” æ£€æŸ¥ç™¾åº¦AI Studioæ•°æ®é›†è´¨é‡...")
        
        baidu_path = os.path.join(base_path, "1.å›¾åƒæ•°æ®ï¼ˆç—…è™«å®³è¯†åˆ«æ ¸å¿ƒï¼‰", 
                                 "ai_challenger_pdr2018")
        
        if not os.path.exists(baidu_path):
            return {'status': 'not_found', 'message': f'è·¯å¾„ä¸å­˜åœ¨: {baidu_path}'}
        
        # æŸ¥æ‰¾æ ‡æ³¨æ–‡ä»¶
        annotation_files = []
        for root, dirs, files in os.walk(baidu_path):
            for file in files:
                if file.endswith('.json'):
                    annotation_files.append(os.path.join(root, file))
        
        # æ”¶é›†å›¾åƒæ–‡ä»¶
        image_files = []
        for root, dirs, files in os.walk(baidu_path):
            for file in files:
                if file.lower().endswith(('.jpg', '.jpeg', '.png')):
                    image_files.append(os.path.join(root, file))
        
        print(f"   æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒï¼Œ{len(annotation_files)} ä¸ªæ ‡æ³¨æ–‡ä»¶")
        
        # é‡‡æ ·æ£€æŸ¥
        if len(image_files) > max_samples:
            import random
            sampled_files = random.sample(image_files, max_samples)
            print(f"   é‡‡æ · {max_samples} å¼ å›¾åƒè¿›è¡Œè´¨é‡æ£€æŸ¥")
        else:
            sampled_files = image_files
        
        # è´¨é‡æ£€æŸ¥
        quality_stats = []
        for i, image_path in enumerate(sampled_files):
            if i % 50 == 0:
                print(f"   æ£€æŸ¥è¿›åº¦: {i}/{len(sampled_files)}")
            
            if not self.check_image_corruption(image_path):
                continue
            
            quality_info = self.check_image_quality(image_path)
            if quality_info:
                quality_stats.append(quality_info)
        
        return {
            'status': 'checked',
            'total_images': len(image_files),
            'sampled_images': len(sampled_files),
            'annotation_files': len(annotation_files),
            'quality_stats': {
                'mean_size': np.mean([q['size'][0] * q['size'][1] for q in quality_stats]) if quality_stats else 0,
                'mean_brightness': np.mean([q['mean_brightness'] for q in quality_stats]) if quality_stats else 0,
                'mean_file_size': np.mean([q['file_size'] for q in quality_stats]) if quality_stats else 0
            }
        }
    
    def generate_cleaning_recommendations(self) -> List[str]:
        """ç”Ÿæˆæ•°æ®æ¸…æ´—å»ºè®®"""
        recommendations = []
        
        # æŸåå›¾åƒ
        if self.issues['corrupted_images']:
            count = len(self.issues['corrupted_images'])
            recommendations.append(f"ğŸ”§ åˆ é™¤ {count} å¼ æŸåçš„å›¾åƒæ–‡ä»¶")
        
        # é‡å¤å›¾åƒ
        if self.issues['duplicate_images']:
            count = len(self.issues['duplicate_images'])
            recommendations.append(f"ğŸ”„ åˆ é™¤ {count} å¼ é‡å¤å›¾åƒä»¥é¿å…è¿‡æ‹Ÿåˆ")
        
        # ä½è´¨é‡å›¾åƒ
        if self.issues['low_quality_images']:
            count = len(self.issues['low_quality_images'])
            quality_issues = defaultdict(int)
            for item in self.issues['low_quality_images']:
                for issue in item['issues']:
                    quality_issues[issue] += 1
            
            recommendations.append(f"âš ï¸  å‘ç° {count} å¼ ä½è´¨é‡å›¾åƒ:")
            for issue, issue_count in quality_issues.items():
                issue_desc = {
                    'too_small': 'å°ºå¯¸è¿‡å°',
                    'too_large': 'å°ºå¯¸è¿‡å¤§', 
                    'extreme_aspect_ratio': 'é•¿å®½æ¯”å¼‚å¸¸',
                    'too_dark': 'è¿‡æš—',
                    'too_bright': 'è¿‡äº®',
                    'low_contrast': 'å¯¹æ¯”åº¦ä½',
                    'file_too_small': 'æ–‡ä»¶è¿‡å°',
                    'file_too_large': 'æ–‡ä»¶è¿‡å¤§'
                }.get(issue, issue)
                recommendations.append(f"   - {issue_desc}: {issue_count} å¼ ")
        
        # æ ¼å¼é—®é¢˜
        if self.issues['format_issues']:
            count = len(self.issues['format_issues'])
            recommendations.append(f"ğŸ“ ä¿®å¤ {count} ä¸ªå›¾åƒæ ¼å¼é—®é¢˜")
        
        # å¦‚æœæ²¡æœ‰ä¸¥é‡é—®é¢˜
        if not any(self.issues.values()):
            recommendations.append("âœ… æ•°æ®é›†è´¨é‡è‰¯å¥½ï¼Œæ— éœ€å¤§è§„æ¨¡æ¸…æ´—")
            recommendations.append("ğŸ’¡ å»ºè®®è¿›è¡Œæ ‡å‡†çš„é¢„å¤„ç†ï¼šå°ºå¯¸æ ‡å‡†åŒ–ã€æ•°æ®å¢å¼ºç­‰")
        
        return recommendations
    
    def print_quality_report(self, plantvillage_result: Dict, baidu_result: Dict):
        """æ‰“å°è´¨é‡æ£€æŸ¥æŠ¥å‘Š"""
        print(f"\nğŸ“‹ æ•°æ®è´¨é‡æ£€æŸ¥æŠ¥å‘Š")
        print("=" * 60)
        
        # PlantVillageæŠ¥å‘Š
        if plantvillage_result['status'] == 'checked':
            print(f"\nğŸŒ± PlantVillageæ•°æ®é›†:")
            print(f"   ğŸ“Š æ€»å›¾åƒæ•°: {plantvillage_result['total_images']}")
            print(f"   ğŸ” æ£€æŸ¥æ ·æœ¬: {plantvillage_result['sampled_images']}")
            
            balance = plantvillage_result['balance_info']
            if balance['balanced']:
                print(f"   âš–ï¸  ç±»åˆ«å¹³è¡¡: âœ… è‰¯å¥½")
            else:
                print(f"   âš–ï¸  ç±»åˆ«å¹³è¡¡: âš ï¸  å­˜åœ¨é—®é¢˜")
                for issue in balance['issues']:
                    print(f"      - {issue}")
            
            stats = plantvillage_result['quality_stats']
            print(f"   ğŸ“ å¹³å‡åˆ†è¾¨ç‡: {stats['mean_size']:.0f} åƒç´ ")
            print(f"   ğŸ’¡ å¹³å‡äº®åº¦: {stats['mean_brightness']:.1f}")
            print(f"   ğŸ“¦ å¹³å‡æ–‡ä»¶å¤§å°: {stats['mean_file_size']/1024:.1f} KB")
        
        # ç™¾åº¦æ•°æ®é›†æŠ¥å‘Š
        if baidu_result['status'] == 'checked':
            print(f"\nğŸ‡¨ğŸ‡³ ç™¾åº¦AI Studioæ•°æ®é›†:")
            print(f"   ğŸ“Š æ€»å›¾åƒæ•°: {baidu_result['total_images']}")
            print(f"   ğŸ” æ£€æŸ¥æ ·æœ¬: {baidu_result['sampled_images']}")
            print(f"   ğŸ“ æ ‡æ³¨æ–‡ä»¶: {baidu_result['annotation_files']} ä¸ª")
            
            stats = baidu_result['quality_stats']
            print(f"   ğŸ“ å¹³å‡åˆ†è¾¨ç‡: {stats['mean_size']:.0f} åƒç´ ")
            print(f"   ğŸ’¡ å¹³å‡äº®åº¦: {stats['mean_brightness']:.1f}")
            print(f"   ğŸ“¦ å¹³å‡æ–‡ä»¶å¤§å°: {stats['mean_file_size']/1024:.1f} KB")
        
        # é—®é¢˜ç»Ÿè®¡
        total_issues = sum(len(issues) for issues in self.issues.values())
        print(f"\nğŸš¨ å‘ç°çš„é—®é¢˜:")
        print(f"   æŸåå›¾åƒ: {len(self.issues['corrupted_images'])} ä¸ª")
        print(f"   é‡å¤å›¾åƒ: {len(self.issues['duplicate_images'])} ä¸ª") 
        print(f"   ä½è´¨é‡å›¾åƒ: {len(self.issues['low_quality_images'])} ä¸ª")
        print(f"   æ ¼å¼é—®é¢˜: {len(self.issues['format_issues'])} ä¸ª")
        print(f"   æ€»é—®é¢˜æ•°: {total_issues} ä¸ª")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” CropPilot æ•°æ®è´¨é‡æ£€æŸ¥å·¥å…·")
    print("=" * 60)
    
    if not PIL_AVAILABLE:
        print("âŒ ç¼ºå°‘å¿…è¦ä¾èµ–ï¼Œè¯·å®‰è£…:")
        print("   pip install Pillow numpy")
        return
    
    base_path = r"C:\Users\hp\Desktop\ä½œç‰©ç”Ÿé•¿çŠ¶æ€ç®¡ç†ä¸å†³ç­–æ”¯æŒç³»ç»Ÿ\æ•°æ®"
    
    checker = DataQualityChecker()
    start_time = time.time()
    
    # æ£€æŸ¥æ•°æ®é›†è´¨é‡
    plantvillage_result = checker.check_plantvillage_dataset(base_path)
    baidu_result = checker.check_baidu_dataset(base_path)
    
    # æ‰“å°æŠ¥å‘Š
    checker.print_quality_report(plantvillage_result, baidu_result)
    
    # ç”Ÿæˆå»ºè®®
    recommendations = checker.generate_cleaning_recommendations()
    
    print(f"\nğŸ’¡ æ•°æ®æ¸…æ´—å»ºè®®")
    print("=" * 60)
    for i, rec in enumerate(recommendations, 1):
        print(f"{i}. {rec}")
    
    # æ€»ç»“
    elapsed_time = time.time() - start_time
    print(f"\nâ±ï¸  è´¨é‡æ£€æŸ¥å®Œæˆï¼Œè€—æ—¶: {elapsed_time:.1f} ç§’")
    
    # æ¸…æ´—å¿…è¦æ€§è¯„ä¼°
    total_issues = sum(len(issues) for issues in checker.issues.values())
    if total_issues == 0:
        print(f"\nâœ… ç»“è®º: æ•°æ®é›†è´¨é‡ä¼˜ç§€ï¼Œå¯ç›´æ¥ç”¨äºè®­ç»ƒ")
    elif total_issues < 100:
        print(f"\nâš ï¸  ç»“è®º: æ•°æ®é›†è´¨é‡è‰¯å¥½ï¼Œå»ºè®®è¿›è¡Œè½»åº¦æ¸…æ´—")
    else:
        print(f"\nğŸ”§ ç»“è®º: å‘ç°è¾ƒå¤šé—®é¢˜ï¼Œå»ºè®®è¿›è¡Œæ•°æ®æ¸…æ´—")
    
    print(f"\nğŸ“‹ ä¸‹ä¸€æ­¥è¡ŒåŠ¨:")
    if total_issues > 0:
        print("1. æ ¹æ®å»ºè®®è¿›è¡Œæ•°æ®æ¸…æ´—")
        print("2. é‡æ–°è¿è¡Œè´¨é‡æ£€æŸ¥éªŒè¯æ¸…æ´—æ•ˆæœ")
        print("3. å¼€å§‹æ¨¡å‹è®­ç»ƒ")
    else:
        print("1. å¯ä»¥ç›´æ¥å¼€å§‹æ¨¡å‹è®­ç»ƒ")
        print("2. å»ºè®®è®¾ç½®é€‚å½“çš„æ•°æ®å¢å¼ºç­–ç•¥")

if __name__ == "__main__":
    main()