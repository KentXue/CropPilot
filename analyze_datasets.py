#!/usr/bin/env python3
"""
æ·±åº¦åˆ†ææ•°æ®é›†å†…å®¹å’Œç»“æ„
é‡æ–°è¯„ä¼°æ•°æ®é›†çš„ç”¨é€”å’Œå…³ç³»
"""

import os
import json
from pathlib import Path
from collections import Counter, defaultdict

def analyze_plantvillage_classes():
    """åˆ†æPlantVillageæ•°æ®é›†çš„ç±»åˆ«"""
    print("ğŸ” åˆ†æPlantVillageæ•°æ®é›†ç±»åˆ«...")
    
    color_path = r"C:\Users\hp\Desktop\ä½œç‰©ç”Ÿé•¿çŠ¶æ€ç®¡ç†ä¸å†³ç­–æ”¯æŒç³»ç»Ÿ\æ•°æ®\1.å›¾åƒæ•°æ®ï¼ˆç—…è™«å®³è¯†åˆ«æ ¸å¿ƒï¼‰\plantvillage dataset\color"
    
    if not os.path.exists(color_path):
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {color_path}")
        return {}
    
    # è·å–æ‰€æœ‰ç±»åˆ«ç›®å½•
    classes = []
    class_counts = {}
    crop_types = defaultdict(list)
    
    for item in os.listdir(color_path):
        item_path = os.path.join(color_path, item)
        if os.path.isdir(item_path):
            classes.append(item)
            # ç»Ÿè®¡è¯¥ç±»åˆ«çš„å›¾ç‰‡æ•°é‡
            img_count = len([f for f in os.listdir(item_path) 
                           if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
            class_counts[item] = img_count
            
            # æå–ä½œç‰©ç±»å‹
            crop_name = item.split('___')[0] if '___' in item else item
            crop_types[crop_name].append(item)
    
    print(f"ğŸ“Š PlantVillageæ•°æ®é›†åˆ†æ:")
    print(f"   æ€»ç±»åˆ«æ•°: {len(classes)}")
    print(f"   ä½œç‰©ç§ç±»: {len(crop_types)}")
    
    print(f"\nğŸŒ± ä½œç‰©ç§ç±»åˆ†å¸ƒ:")
    for crop, diseases in crop_types.items():
        total_images = sum(class_counts.get(disease, 0) for disease in diseases)
        print(f"   {crop}: {len(diseases)} ç§ç—…å®³, {total_images} å¼ å›¾ç‰‡")
        for disease in diseases[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªç—…å®³
            print(f"     - {disease}: {class_counts.get(disease, 0)} å¼ ")
        if len(diseases) > 3:
            print(f"     ... è¿˜æœ‰ {len(diseases) - 3} ç§ç—…å®³")
    
    return crop_types, class_counts

def analyze_baidu_dataset():
    """åˆ†æç™¾åº¦AI Studioæ•°æ®é›†"""
    print(f"\nğŸ” åˆ†æç™¾åº¦AI Studioæ•°æ®é›†...")
    
    baidu_path = r"C:\Users\hp\Desktop\ä½œç‰©ç”Ÿé•¿çŠ¶æ€ç®¡ç†ä¸å†³ç­–æ”¯æŒç³»ç»Ÿ\æ•°æ®\1.å›¾åƒæ•°æ®ï¼ˆç—…è™«å®³è¯†åˆ«æ ¸å¿ƒï¼‰\ai_challenger_pdr2018"
    
    if not os.path.exists(baidu_path):
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {baidu_path}")
        return {}
    
    # æŸ¥æ‰¾æ‰€æœ‰æ–‡ä»¶
    all_files = []
    json_files = []
    image_files = []
    
    for root, dirs, files in os.walk(baidu_path):
        for file in files:
            file_path = os.path.join(root, file)
            all_files.append(file_path)
            
            if file.endswith('.json'):
                json_files.append(file_path)
            elif file.lower().endswith(('.jpg', '.jpeg', '.png')):
                image_files.append(file_path)
    
    print(f"ğŸ“Š ç™¾åº¦AI Studioæ•°æ®é›†åˆ†æ:")
    print(f"   æ€»æ–‡ä»¶æ•°: {len(all_files)}")
    print(f"   å›¾åƒæ–‡ä»¶: {len(image_files)}")
    print(f"   JSONæ–‡ä»¶: {len(json_files)}")
    
    # åˆ†æç›®å½•ç»“æ„
    print(f"\nğŸ“ ç›®å½•ç»“æ„:")
    for root, dirs, files in os.walk(baidu_path):
        level = root.replace(baidu_path, '').count(os.sep)
        indent = ' ' * 2 * level
        folder_name = os.path.basename(root)
        if folder_name:
            print(f"{indent}{folder_name}/ ({len(files)} æ–‡ä»¶)")
    
    # åˆ†æJSONæ ‡æ³¨æ–‡ä»¶
    if json_files:
        print(f"\nğŸ“ æ ‡æ³¨æ–‡ä»¶åˆ†æ:")
        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                file_name = os.path.basename(json_file)
                print(f"   {file_name}:")
                
                if isinstance(data, list):
                    print(f"     ç±»å‹: åˆ—è¡¨, é•¿åº¦: {len(data)}")
                    if data:
                        sample = data[0]
                        print(f"     æ ·æœ¬å­—æ®µ: {list(sample.keys()) if isinstance(sample, dict) else 'N/A'}")
                elif isinstance(data, dict):
                    print(f"     ç±»å‹: å­—å…¸, å­—æ®µ: {list(data.keys())}")
                
            except Exception as e:
                print(f"     âŒ æ— æ³•è§£æ: {e}")
    
    return {
        'total_files': len(all_files),
        'image_files': len(image_files),
        'json_files': len(json_files),
        'json_paths': json_files
    }

def analyze_phenology_dataset():
    """åˆ†æç‰©å€™æ•°æ®é›†"""
    print(f"\nğŸ” åˆ†æç‰©å€™æ•°æ®é›†...")
    
    phenology_path = r"C:\Users\hp\Desktop\ä½œç‰©ç”Ÿé•¿çŠ¶æ€ç®¡ç†ä¸å†³ç­–æ”¯æŒç³»ç»Ÿ\æ•°æ®\2.ç”Ÿé•¿æ•°æ®ï¼ˆæ—¶é—´åºåˆ—ï¼‰\8313530"
    
    if not os.path.exists(phenology_path):
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {phenology_path}")
        return {}
    
    # åˆ†ææ–‡ä»¶ç±»å‹å’Œæ•°é‡
    file_types = defaultdict(int)
    total_size = 0
    
    for root, dirs, files in os.walk(phenology_path):
        for file in files:
            file_path = os.path.join(root, file)
            ext = os.path.splitext(file)[1].lower()
            file_types[ext] += 1
            
            try:
                total_size += os.path.getsize(file_path)
            except:
                pass
    
    print(f"ğŸ“Š ç‰©å€™æ•°æ®é›†åˆ†æ:")
    print(f"   æ€»å¤§å°: {total_size / (1024**3):.1f} GB")
    print(f"   æ–‡ä»¶ç±»å‹åˆ†å¸ƒ:")
    for ext, count in sorted(file_types.items(), key=lambda x: x[1], reverse=True):
        print(f"     {ext or 'æ— æ‰©å±•å'}: {count} ä¸ª")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¯´æ˜æ–‡ä»¶
    readme_files = []
    for root, dirs, files in os.walk(phenology_path):
        for file in files:
            if any(keyword in file.lower() for keyword in ['readme', 'description', 'è¯´æ˜', 'info']):
                readme_files.append(os.path.join(root, file))
    
    if readme_files:
        print(f"\nğŸ“– è¯´æ˜æ–‡ä»¶:")
        for readme in readme_files:
            print(f"   {os.path.basename(readme)}")
    
    return {
        'total_size_gb': total_size / (1024**3),
        'file_types': dict(file_types),
        'readme_files': readme_files
    }

def generate_dataset_strategy():
    """ç”Ÿæˆæ•°æ®é›†ä½¿ç”¨ç­–ç•¥"""
    print(f"\nğŸ’¡ æ•°æ®é›†ä½¿ç”¨ç­–ç•¥å»ºè®®")
    print("=" * 60)
    
    print(f"ğŸ¯ æ¨èçš„è®­ç»ƒç­–ç•¥:")
    print(f"1. **ä¸»è¦è®­ç»ƒæ•°æ®é›†**: PlantVillage Color")
    print(f"   - ä¼˜ç‚¹: 54,000+å¼ é«˜è´¨é‡æ ‡æ³¨å›¾åƒï¼Œ38ä¸ªç—…å®³ç±»åˆ«")
    print(f"   - ç”¨é€”: ä¸»è¦è®­ç»ƒé›†ï¼Œå»ºç«‹åŸºç¡€è¯†åˆ«èƒ½åŠ›")
    print(f"   - ä½œç‰©: è‹¹æœã€ç‰ç±³ã€ç•ªèŒ„ã€é©¬é“ƒè–¯ç­‰14ç§å›½é™…å¸¸è§ä½œç‰©")
    
    print(f"\n2. **è¾…åŠ©è®­ç»ƒæ•°æ®é›†**: PlantVillage Segmented")
    print(f"   - ä¼˜ç‚¹: èƒŒæ™¯å·²åˆ†ç¦»ï¼Œæœ‰åŠ©äºæé«˜è¯†åˆ«ç²¾åº¦")
    print(f"   - ç”¨é€”: ç²¾åº¦ä¼˜åŒ–é˜¶æ®µä½¿ç”¨")
    print(f"   - å»ºè®®: ä¸Coloræ•°æ®é›†ç»“åˆä½¿ç”¨")
    
    print(f"\n3. **ä¸­å›½æœ¬åœŸåŒ–æ•°æ®é›†**: ç™¾åº¦AI Studio")
    print(f"   - ä¼˜ç‚¹: ä¸­å›½æœ¬åœŸå†œä½œç‰©ï¼Œæ›´ç¬¦åˆå®é™…åº”ç”¨åœºæ™¯")
    print(f"   - ç”¨é€”: æ¨¡å‹å¾®è°ƒå’Œæœ¬åœŸåŒ–é€‚é…")
    print(f"   - æ³¨æ„: éœ€è¦å…ˆåˆ†ææ ‡æ³¨æ ¼å¼å’Œç±»åˆ«æ˜ å°„")
    
    print(f"\n4. **ç‰©å€™æ•°æ®é›†**: æ—¶é—´åºåˆ—æ•°æ®")
    print(f"   - ç”¨é€”: æä¾›æ—¶ç©ºä¸Šä¸‹æ–‡ä¿¡æ¯")
    print(f"   - åº”ç”¨: ç»“åˆåœ°ç†ä½ç½®å’Œæ—¶é—´ä¿¡æ¯å¢å¼ºè¯†åˆ«å‡†ç¡®æ€§")
    print(f"   - å®ç°: ä½œä¸ºè¾…åŠ©ç‰¹å¾ï¼Œä¸æ˜¯ä¸»è¦è®­ç»ƒæ•°æ®")
    
    print(f"\nğŸ”„ å»ºè®®çš„è®­ç»ƒæµç¨‹:")
    print(f"   é˜¶æ®µ1: ä½¿ç”¨PlantVillage Colorè®­ç»ƒåŸºç¡€æ¨¡å‹")
    print(f"   é˜¶æ®µ2: ä½¿ç”¨PlantVillage Segmentedè¿›è¡Œç²¾åº¦ä¼˜åŒ–")
    print(f"   é˜¶æ®µ3: ä½¿ç”¨ç™¾åº¦æ•°æ®é›†è¿›è¡Œä¸­å›½æœ¬åœŸåŒ–å¾®è°ƒ")
    print(f"   é˜¶æ®µ4: é›†æˆç‰©å€™æ•°æ®æä¾›ä¸Šä¸‹æ–‡å¢å¼º")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ CropPilot æ•°æ®é›†æ·±åº¦åˆ†æ")
    print("=" * 60)
    
    # åˆ†æå„ä¸ªæ•°æ®é›†
    plantvillage_crops, plantvillage_counts = analyze_plantvillage_classes()
    baidu_info = analyze_baidu_dataset()
    phenology_info = analyze_phenology_dataset()
    
    # ç”Ÿæˆç­–ç•¥å»ºè®®
    generate_dataset_strategy()
    
    print(f"\nğŸ“‹ åˆ†æå®Œæˆ!")
    print(f"å»ºè®®: é‡æ–°è®¾è®¡æ•°æ®é›†é…ç½®ï¼Œæ˜ç¡®å„æ•°æ®é›†çš„ç”¨é€”")

if __name__ == "__main__":
    main()