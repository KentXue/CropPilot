# AIå›¾åƒè¯†åˆ«å®æ–½è®¡åˆ’

## ğŸ“Š æ•°æ®èµ„æºæ¦‚è§ˆ

ä½ å·²æ‹¥æœ‰çš„æ•°æ®é›†ï¼š
1. **PlantVillageæ•°æ®é›†**: 54,000+å¼ é«˜è´¨é‡æ ‡æ³¨å›¾åƒï¼ˆ2GBï¼‰
2. **ç™¾åº¦AI Studioå†œä¸šæ•°æ®é›†**: Training Set + Validation Setï¼ˆ3.2GBï¼‰
3. **ChinaCropPhen1kmç‰©å€™æ•°æ®é›†**: 2000-2019å¹´æ—¶é—´åºåˆ—ï¼ˆ8GBï¼‰

## ğŸ¯ å®æ–½é˜¶æ®µ

### é˜¶æ®µ1: æ•°æ®å‡†å¤‡å’Œé¢„å¤„ç†ï¼ˆ1-2å‘¨ï¼‰

#### 1.1 æ•°æ®é›†æ•´åˆ
```bash
# å»ºè®®çš„ç›®å½•ç»“æ„
datasets/
â”œâ”€â”€ plantvillage/
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ val/
â”‚   â””â”€â”€ test/
â”œâ”€â”€ baidu_ai_studio/
â”‚   â”œâ”€â”€ training_set/
â”‚   â””â”€â”€ validation_set/
â””â”€â”€ china_crop_phen/
    â”œâ”€â”€ rice/
    â”œâ”€â”€ wheat/
    â””â”€â”€ corn/
```

#### 1.2 æ•°æ®æ¸…æ´—å’ŒéªŒè¯
- æ£€æŸ¥å›¾ç‰‡å®Œæ•´æ€§å’Œæ ¼å¼
- éªŒè¯æ ‡æ³¨ä¸€è‡´æ€§
- ç»Ÿä¸€ç±»åˆ«æ˜ å°„
- æ•°æ®è´¨é‡è¯„ä¼°

#### 1.3 æ•°æ®é¢„å¤„ç†è„šæœ¬
```python
# éœ€è¦åˆ›å»ºçš„è„šæœ¬
scripts/
â”œâ”€â”€ data_loader.py          # æ•°æ®åŠ è½½å™¨
â”œâ”€â”€ data_preprocessor.py    # å›¾åƒé¢„å¤„ç†
â”œâ”€â”€ dataset_merger.py       # æ•°æ®é›†åˆå¹¶
â””â”€â”€ data_validator.py       # æ•°æ®éªŒè¯
```

### é˜¶æ®µ2: æ¨¡å‹æ¶æ„è®¾è®¡ï¼ˆ1å‘¨ï¼‰

#### 2.1 é€‰æ‹©åˆé€‚çš„CNNæ¶æ„
- **ä¸»æ¨¡å‹**: EfficientNet-B4 æˆ– ResNet50ï¼ˆæ¯”ResNet18æ›´å¼ºï¼‰
- **å¤‡é€‰**: Vision Transformer (ViT) ç”¨äºé«˜ç²¾åº¦éœ€æ±‚
- **è½»é‡çº§**: MobileNetV3 ç”¨äºç§»åŠ¨ç«¯éƒ¨ç½²

#### 2.2 å¤šä»»åŠ¡å­¦ä¹ æ¶æ„
```python
class PlantDiseaseClassifier(nn.Module):
    def __init__(self):
        # ä¸»å¹²ç½‘ç»œï¼šç‰¹å¾æå–
        self.backbone = EfficientNet.from_pretrained('efficientnet-b4')
        
        # å¤šä¸ªåˆ†ç±»å¤´
        self.disease_classifier = nn.Linear(1792, num_diseases)
        self.crop_classifier = nn.Linear(1792, num_crops)
        self.severity_classifier = nn.Linear(1792, 4)  # è½»å¾®/ä¸­ç­‰/ä¸¥é‡/å¥åº·
```

#### 2.3 ç‰©å€™æœŸé›†æˆæ¨¡å—
```python
class PhenologyModule:
    def __init__(self):
        # åŠ è½½ChinaCropPhen1kmæ•°æ®
        # æ ¹æ®åœ°ç†ä½ç½®å’Œæ—¶é—´æ¨æ–­ç‰©å€™æœŸ
        pass
    
    def get_phenology_context(self, location, date, crop_type):
        # è¿”å›å½“å‰ç‰©å€™æœŸä¿¡æ¯
        pass
```

### é˜¶æ®µ3: æ¨¡å‹è®­ç»ƒï¼ˆ2-3å‘¨ï¼‰

#### 3.1 è®­ç»ƒç­–ç•¥
```python
# è®­ç»ƒé…ç½®
BATCH_SIZE = 32
LEARNING_RATE = 0.001
EPOCHS = 100
EARLY_STOPPING_PATIENCE = 10

# æ•°æ®å¢å¼º
transforms = A.Compose([
    A.RandomRotate90(),
    A.Flip(),
    A.RandomBrightnessContrast(),
    A.HueSaturationValue(),
    A.CoarseDropout(max_holes=8, max_height=32, max_width=32),
    A.Normalize(),
    ToTensorV2()
])
```

#### 3.2 åˆ†é˜¶æ®µè®­ç»ƒ
1. **é¢„è®­ç»ƒ**: åœ¨PlantVillageä¸Šé¢„è®­ç»ƒ
2. **å¾®è°ƒ**: åœ¨ç™¾åº¦AI Studioæ•°æ®ä¸Šå¾®è°ƒ
3. **é›†æˆ**: ç»“åˆç‰©å€™æ•°æ®è¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ 

#### 3.3 è®­ç»ƒç›‘æ§
```python
# ä½¿ç”¨Weights & Biasesæˆ–TensorBoard
import wandb

wandb.init(project="crop-disease-recognition")
wandb.config.update({
    "learning_rate": LEARNING_RATE,
    "batch_size": BATCH_SIZE,
    "architecture": "EfficientNet-B4"
})
```

### é˜¶æ®µ4: æ¨¡å‹ä¼˜åŒ–å’Œéƒ¨ç½²ï¼ˆ1-2å‘¨ï¼‰

#### 4.1 æ¨¡å‹å‹ç¼©
```python
# é‡åŒ–å’Œå‰ªæ
import torch.quantization as quantization

# åŠ¨æ€é‡åŒ–
quantized_model = torch.quantization.quantize_dynamic(
    model, {torch.nn.Linear}, dtype=torch.qint8
)

# æ¨¡å‹å‰ªæ
import torch.nn.utils.prune as prune
prune.global_unstructured(
    parameters_to_prune,
    pruning_method=prune.L1Unstructured,
    amount=0.2,
)
```

#### 4.2 æ¨ç†ä¼˜åŒ–
```python
# TorchScriptä¼˜åŒ–
traced_model = torch.jit.trace(model, example_input)
traced_model.save("optimized_model.pt")

# ONNXå¯¼å‡ºï¼ˆå¯é€‰ï¼‰
torch.onnx.export(model, example_input, "model.onnx")
```

## ğŸ› ï¸ å…·ä½“å®æ–½æ­¥éª¤

### ç¬¬1æ­¥: ç¯å¢ƒå‡†å¤‡
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv crop_ai_env
source crop_ai_env/bin/activate  # Linux/Mac
# crop_ai_env\Scripts\activate  # Windows

# å®‰è£…ä¾èµ–
pip install torch torchvision torchaudio
pip install timm  # ç°ä»£CNNæ¶æ„
pip install albumentations  # æ•°æ®å¢å¼º
pip install wandb  # å®éªŒè·Ÿè¸ª
pip install opencv-python
pip install pandas numpy matplotlib seaborn
```

### ç¬¬2æ­¥: æ•°æ®é›†å‡†å¤‡è„šæœ¬
```python
# scripts/prepare_datasets.py
import os
import shutil
from pathlib import Path
import pandas as pd
from PIL import Image
import json

class DatasetPreparer:
    def __init__(self, data_root="datasets"):
        self.data_root = Path(data_root)
        self.data_root.mkdir(exist_ok=True)
    
    def prepare_plantvillage(self, source_path):
        """å‡†å¤‡PlantVillageæ•°æ®é›†"""
        print("å‡†å¤‡PlantVillageæ•°æ®é›†...")
        # è§£å‹å’Œæ•´ç†PlantVillageæ•°æ®
        pass
    
    def prepare_baidu_dataset(self, source_path):
        """å‡†å¤‡ç™¾åº¦AI Studioæ•°æ®é›†"""
        print("å‡†å¤‡ç™¾åº¦AI Studioæ•°æ®é›†...")
        # å¤„ç†ç™¾åº¦æ•°æ®é›†æ ¼å¼
        pass
    
    def prepare_phenology_data(self, source_path):
        """å‡†å¤‡ç‰©å€™æ•°æ®"""
        print("å‡†å¤‡ChinaCropPhen1kmæ•°æ®...")
        # å¤„ç†æ …æ ¼æ•°æ®ï¼Œæå–å…³é”®ç‰©å€™æœŸ
        pass
    
    def create_unified_dataset(self):
        """åˆ›å»ºç»Ÿä¸€çš„æ•°æ®é›†æ ¼å¼"""
        # åˆå¹¶å¤šä¸ªæ•°æ®æº
        # åˆ›å»ºç»Ÿä¸€çš„æ ‡æ³¨æ ¼å¼
        pass
```

### ç¬¬3æ­¥: è®­ç»ƒè„šæœ¬æ¡†æ¶
```python
# scripts/train_model.py
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import timm
import wandb
from tqdm import tqdm

class CropDiseaseTrainer:
    def __init__(self, config):
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = timm.create_model(
            'efficientnet_b4', 
            pretrained=True, 
            num_classes=config['num_classes']
        )
        
        # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        self.criterion = nn.CrossEntropyLoss()
        self.optimizer = torch.optim.AdamW(
            self.model.parameters(), 
            lr=config['learning_rate']
        )
        
    def train_epoch(self, dataloader):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        correct = 0
        total = 0
        
        for batch_idx, (data, target) in enumerate(tqdm(dataloader)):
            data, target = data.to(self.device), target.to(self.device)
            
            self.optimizer.zero_grad()
            output = self.model(data)
            loss = self.criterion(output, target)
            loss.backward()
            self.optimizer.step()
            
            total_loss += loss.item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
            total += target.size(0)
            
        return total_loss / len(dataloader), 100. * correct / total
    
    def validate(self, dataloader):
        """éªŒè¯æ¨¡å‹"""
        self.model.eval()
        total_loss = 0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for data, target in dataloader:
                data, target = data.to(self.device), target.to(self.device)
                output = self.model(data)
                loss = self.criterion(output, target)
                
                total_loss += loss.item()
                pred = output.argmax(dim=1, keepdim=True)
                correct += pred.eq(target.view_as(pred)).sum().item()
                total += target.size(0)
        
        return total_loss / len(dataloader), 100. * correct / total
```

### ç¬¬4æ­¥: é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿ
```python
# æ›´æ–° src/image_recognition.py
class EnhancedPlantDiseaseClassifier:
    def __init__(self):
        self.model = self.load_trained_model()
        self.phenology_module = PhenologyModule()
        
    def load_trained_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        model = timm.create_model('efficientnet_b4', num_classes=NUM_CLASSES)
        model.load_state_dict(torch.load('models/trained_model.pth'))
        return model
    
    def analyze_with_context(self, image_path, location=None, date=None):
        """ç»“åˆç‰©å€™æœŸä¸Šä¸‹æ–‡çš„åˆ†æ"""
        # åŸºç¡€å›¾åƒè¯†åˆ«
        base_result = self.analyze_image(image_path)
        
        # ç‰©å€™æœŸä¸Šä¸‹æ–‡
        if location and date:
            phenology_context = self.phenology_module.get_context(location, date)
            # è°ƒæ•´è¯†åˆ«ç»“æœçš„æ¦‚ç‡åˆ†å¸ƒ
            adjusted_result = self.adjust_with_phenology(base_result, phenology_context)
            return adjusted_result
        
        return base_result
```

## ğŸ“ˆ é¢„æœŸæ€§èƒ½æŒ‡æ ‡

### ç›®æ ‡å‡†ç¡®ç‡
- **æ€»ä½“å‡†ç¡®ç‡**: â‰¥ 85%
- **Top-3å‡†ç¡®ç‡**: â‰¥ 95%
- **æ¨ç†é€Ÿåº¦**: < 2ç§’/å¼ ï¼ˆCPUï¼‰, < 0.5ç§’/å¼ ï¼ˆGPUï¼‰
- **æ¨¡å‹å¤§å°**: < 100MBï¼ˆå‹ç¼©åï¼‰

### è¯„ä¼°æŒ‡æ ‡
```python
# è¯„ä¼°è„šæœ¬
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

def evaluate_model(model, test_loader, class_names):
    y_true = []
    y_pred = []
    
    model.eval()
    with torch.no_grad():
        for data, target in test_loader:
            output = model(data)
            pred = output.argmax(dim=1)
            y_true.extend(target.cpu().numpy())
            y_pred.extend(pred.cpu().numpy())
    
    # åˆ†ç±»æŠ¥å‘Š
    report = classification_report(y_true, y_pred, target_names=class_names)
    print(report)
    
    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(12, 10))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=class_names, yticklabels=class_names)
    plt.title('Confusion Matrix')
    plt.show()
```

## ğŸš€ éƒ¨ç½²ç­–ç•¥

### ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
```python
# ç”Ÿäº§ç¯å¢ƒæ¨ç†æœåŠ¡
class ProductionInferenceService:
    def __init__(self):
        # åŠ è½½ä¼˜åŒ–åçš„æ¨¡å‹
        self.model = torch.jit.load('models/optimized_model.pt')
        self.model.eval()
        
    def predict(self, image_bytes):
        """ç”Ÿäº§ç¯å¢ƒé¢„æµ‹æ¥å£"""
        # å›¾åƒé¢„å¤„ç†
        image = self.preprocess_image(image_bytes)
        
        # æ¨¡å‹æ¨ç†
        with torch.no_grad():
            output = self.model(image)
            probabilities = torch.softmax(output, dim=1)
            
        return self.format_results(probabilities)
```

## ğŸ“‹ æ—¶é—´çº¿

| é˜¶æ®µ | ä»»åŠ¡ | é¢„è®¡æ—¶é—´ | å…³é”®é‡Œç¨‹ç¢‘ |
|------|------|----------|------------|
| 1 | æ•°æ®å‡†å¤‡ | 1-2å‘¨ | æ•°æ®é›†æ•´åˆå®Œæˆ |
| 2 | æ¨¡å‹è®¾è®¡ | 1å‘¨ | æ¶æ„ç¡®å®š |
| 3 | æ¨¡å‹è®­ç»ƒ | 2-3å‘¨ | è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡ |
| 4 | ä¼˜åŒ–éƒ¨ç½² | 1-2å‘¨ | ç”Ÿäº§ç¯å¢ƒå°±ç»ª |

**æ€»è®¡**: 5-8å‘¨å®Œæˆå®Œæ•´çš„AIå›¾åƒè¯†åˆ«ç³»ç»Ÿ

è¿™ä¸ªè®¡åˆ’å……åˆ†åˆ©ç”¨äº†ä½ ç°æœ‰çš„æ•°æ®èµ„æºï¼Œä½ è§‰å¾—è¿™ä¸ªå®æ–½æ–¹æ¡ˆå¦‚ä½•ï¼Ÿéœ€è¦æˆ‘è¯¦ç»†è§£é‡Šä»»ä½•ç‰¹å®šçš„æ­¥éª¤å—ï¼Ÿ