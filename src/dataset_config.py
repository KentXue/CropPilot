#!/usr/bin/env python3
"""
æ•°æ®é›†é…ç½®æ–‡ä»¶
å®šä¹‰æ‰€æœ‰æ•°æ®é›†çš„è·¯å¾„å’Œå‚æ•°é…ç½®
"""

import os
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple
from pathlib import Path

@dataclass
class ImageDatasetConfig:
    """å›¾åƒæ•°æ®é›†é…ç½®"""
    name: str
    path: str
    description: str
    image_extensions: List[str]
    expected_classes: int
    input_size: Tuple[int, int]
    enabled: bool = True
    has_subdirectories: bool = True

@dataclass
class PhenologyDatasetConfig:
    """ç‰©å€™æ•°æ®é›†é…ç½®"""
    name: str
    path: str
    description: str
    data_extensions: List[str]
    temporal_range: Tuple[int, int]  # å¹´ä»½èŒƒå›´
    spatial_resolution: str
    enabled: bool = True

class CropPilotDatasetConfig:
    """CropPiloté¡¹ç›®æ•°æ®é›†é…ç½®ç®¡ç†"""
    
    def __init__(self, base_data_path: str = None):
        """
        åˆå§‹åŒ–æ•°æ®é›†é…ç½®
        
        Args:
            base_data_path: æ•°æ®é›†åŸºç¡€è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
        """
        if base_data_path is None:
            # é»˜è®¤æ•°æ®é›†è·¯å¾„
            self.base_data_path = r"C:\Users\hp\Desktop\ä½œç‰©ç”Ÿé•¿çŠ¶æ€ç®¡ç†ä¸å†³ç­–æ”¯æŒç³»ç»Ÿ\æ•°æ®"
        else:
            self.base_data_path = base_data_path
        
        self._setup_datasets()
    
    def _setup_datasets(self):
        """è®¾ç½®æ‰€æœ‰æ•°æ®é›†é…ç½®"""
        
        # PlantVillageæ•°æ®é›†é…ç½®
        plantvillage_base = os.path.join(
            self.base_data_path, 
            "1.å›¾åƒæ•°æ®ï¼ˆç—…è™«å®³è¯†åˆ«æ ¸å¿ƒï¼‰", 
            "plantvillage dataset"
        )
        
        self.plantvillage_datasets = {
            'color': ImageDatasetConfig(
                name="PlantVillage_Color",
                path=os.path.join(plantvillage_base, "color"),
                description="PlantVillageå½©è‰²å›¾åƒæ•°æ®é›†",
                image_extensions=['.jpg', '.jpeg', '.png'],
                expected_classes=38,
                input_size=(224, 224),
                has_subdirectories=True
            ),
            'grayscale': ImageDatasetConfig(
                name="PlantVillage_Grayscale", 
                path=os.path.join(plantvillage_base, "grayscale"),
                description="PlantVillageç°åº¦å›¾åƒæ•°æ®é›†",
                image_extensions=['.jpg', '.jpeg', '.png'],
                expected_classes=38,
                input_size=(224, 224),
                has_subdirectories=True
            ),
            'segmented': ImageDatasetConfig(
                name="PlantVillage_Segmented",
                path=os.path.join(plantvillage_base, "segmented"), 
                description="PlantVillageåˆ†å‰²å›¾åƒæ•°æ®é›†",
                image_extensions=['.jpg', '.jpeg', '.png'],
                expected_classes=38,
                input_size=(224, 224),
                has_subdirectories=True
            )
        }
        
        # ç™¾åº¦AI Studioæ•°æ®é›†é…ç½®
        self.baidu_dataset = ImageDatasetConfig(
            name="Baidu_AI_Studio",
            path=os.path.join(
                self.base_data_path,
                "1.å›¾åƒæ•°æ®ï¼ˆç—…è™«å®³è¯†åˆ«æ ¸å¿ƒï¼‰",
                "ai_challenger_pdr2018"
            ),
            description="ç™¾åº¦AI Studioæ¤ç‰©ç—…å®³æ•°æ®é›†",
            image_extensions=['.jpg', '.jpeg', '.png'],
            expected_classes=0,  # éœ€è¦ä»æ ‡æ³¨æ–‡ä»¶ä¸­ç¡®å®š
            input_size=(224, 224),
            has_subdirectories=False
        )
        
        # ç‰©å€™æ•°æ®é›†é…ç½®
        self.phenology_dataset = PhenologyDatasetConfig(
            name="ChinaCropPhen1km",
            path=os.path.join(
                self.base_data_path,
                "2.ç”Ÿé•¿æ•°æ®ï¼ˆæ—¶é—´åºåˆ—ï¼‰",
                "8313530"
            ),
            description="ä¸­å›½ä½œç‰©ç‰©å€™1kmåˆ†è¾¨ç‡æ•°æ®é›†",
            data_extensions=['.tif', '.tiff', '.nc', '.hdf'],
            temporal_range=(2000, 2019),
            spatial_resolution="1km"
        )
    
    def get_primary_dataset_config(self) -> ImageDatasetConfig:
        """è·å–ä¸»è¦è®­ç»ƒæ•°æ®é›†é…ç½®ï¼ˆPlantVillage Colorç”¨äºåŸºç¡€è®­ç»ƒï¼‰"""
        return self.plantvillage_datasets['color']
    
    def get_validation_dataset_config(self) -> ImageDatasetConfig:
        """è·å–éªŒè¯æ•°æ®é›†é…ç½®ï¼ˆç™¾åº¦æ•°æ®é›†ç”¨äºä¸­å›½æœ¬åœŸåŒ–éªŒè¯ï¼‰"""
        return self.baidu_dataset
    
    def get_enhancement_dataset_config(self) -> ImageDatasetConfig:
        """è·å–ç²¾åº¦å¢å¼ºæ•°æ®é›†é…ç½®ï¼ˆSegmentedç”¨äºç²¾åº¦ä¼˜åŒ–ï¼‰"""
        return self.plantvillage_datasets['segmented']
    
    def get_all_image_datasets(self) -> Dict[str, ImageDatasetConfig]:
        """è·å–æ‰€æœ‰å›¾åƒæ•°æ®é›†é…ç½®"""
        datasets = {}
        datasets.update(self.plantvillage_datasets)
        datasets['baidu'] = self.baidu_dataset
        return datasets
    
    def get_phenology_config(self) -> PhenologyDatasetConfig:
        """è·å–ç‰©å€™æ•°æ®é›†é…ç½®"""
        return self.phenology_dataset
    
    def validate_paths(self) -> Dict[str, bool]:
        """éªŒè¯æ‰€æœ‰æ•°æ®é›†è·¯å¾„æ˜¯å¦å­˜åœ¨"""
        results = {}
        
        # æ£€æŸ¥PlantVillageæ•°æ®é›†
        for name, config in self.plantvillage_datasets.items():
            results[f"plantvillage_{name}"] = os.path.exists(config.path)
        
        # æ£€æŸ¥ç™¾åº¦æ•°æ®é›†
        results["baidu"] = os.path.exists(self.baidu_dataset.path)
        
        # æ£€æŸ¥ç‰©å€™æ•°æ®é›†
        results["phenology"] = os.path.exists(self.phenology_dataset.path)
        
        return results
    
    def get_dataset_summary(self) -> Dict[str, any]:
        """è·å–æ•°æ®é›†é…ç½®æ‘˜è¦"""
        path_status = self.validate_paths()
        
        return {
            'base_path': self.base_data_path,
            'plantvillage_datasets': len(self.plantvillage_datasets),
            'total_image_datasets': len(self.get_all_image_datasets()),
            'has_phenology_data': path_status.get('phenology', False),
            'path_validation': path_status,
            'training_strategy': {
                'primary_training': self.get_primary_dataset_config().name,
                'localization_validation': self.get_validation_dataset_config().name,
                'precision_enhancement': self.get_enhancement_dataset_config().name,
                'context_data': self.get_phenology_config().name
            },
            'recommended_workflow': [
                "é˜¶æ®µ1: PlantVillage ColoråŸºç¡€è®­ç»ƒ",
                "é˜¶æ®µ2: PlantVillage Segmentedç²¾åº¦ä¼˜åŒ–", 
                "é˜¶æ®µ3: ç™¾åº¦æ•°æ®é›†ä¸­å›½æœ¬åœŸåŒ–å¾®è°ƒ",
                "é˜¶æ®µ4: ç‰©å€™æ•°æ®ä¸Šä¸‹æ–‡å¢å¼º"
            ]
        }

# å…¨å±€é…ç½®å®ä¾‹
dataset_config = CropPilotDatasetConfig()

# ä¾¿æ·è®¿é—®å‡½æ•°
def get_dataset_config() -> CropPilotDatasetConfig:
    """è·å–å…¨å±€æ•°æ®é›†é…ç½®å®ä¾‹"""
    return dataset_config

def get_primary_dataset_path() -> str:
    """è·å–ä¸»è¦è®­ç»ƒæ•°æ®é›†è·¯å¾„"""
    return dataset_config.get_primary_dataset_config().path

def get_validation_dataset_path() -> str:
    """è·å–éªŒè¯æ•°æ®é›†è·¯å¾„"""
    return dataset_config.get_validation_dataset_config().path

if __name__ == "__main__":
    # æµ‹è¯•é…ç½®
    print("ğŸ”§ CropPilot æ•°æ®é›†é…ç½®æµ‹è¯•")
    print("=" * 50)
    
    config = get_dataset_config()
    summary = config.get_dataset_summary()
    
    print(f"ğŸ“ åŸºç¡€è·¯å¾„: {summary['base_path']}")
    print(f"ğŸ“Š PlantVillageæ•°æ®é›†: {summary['plantvillage_datasets']} ä¸ª")
    print(f"ğŸ“Š æ€»å›¾åƒæ•°æ®é›†: {summary['total_image_datasets']} ä¸ª")
    print(f"ğŸŒ± ç‰©å€™æ•°æ®: {'âœ…' if summary['has_phenology_data'] else 'âŒ'}")
    print(f"ğŸ¯ è®­ç»ƒç­–ç•¥:")
    for stage in summary['recommended_workflow']:
        print(f"   {stage}")
    
    print(f"\nğŸ“Š æ•°æ®é›†è§’è‰²:")
    strategy = summary['training_strategy']
    print(f"   ä¸»è¦è®­ç»ƒ: {strategy['primary_training']}")
    print(f"   æœ¬åœŸåŒ–éªŒè¯: {strategy['localization_validation']}")
    print(f"   ç²¾åº¦å¢å¼º: {strategy['precision_enhancement']}")
    print(f"   ä¸Šä¸‹æ–‡æ•°æ®: {strategy['context_data']}")
    
    print(f"\nğŸ“‹ è·¯å¾„éªŒè¯ç»“æœ:")
    for dataset_name, exists in summary['path_validation'].items():
        status = "âœ…" if exists else "âŒ"
        print(f"   {dataset_name}: {status}")
    
    # æ˜¾ç¤ºä¸»è¦æ•°æ®é›†è¯¦æƒ…
    primary_config = config.get_primary_dataset_config()
    print(f"\nğŸ¯ ä¸»è¦æ•°æ®é›†è¯¦æƒ…:")
    print(f"   åç§°: {primary_config.name}")
    print(f"   è·¯å¾„: {primary_config.path}")
    print(f"   æè¿°: {primary_config.description}")
    print(f"   é¢„æœŸç±»åˆ«: {primary_config.expected_classes}")
    print(f"   è¾“å…¥å°ºå¯¸: {primary_config.input_size}")