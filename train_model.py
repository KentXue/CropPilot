#!/usr/bin/env python3
"""
æ¤ç‰©ç—…å®³è¯†åˆ«æ¨¡å‹è®­ç»ƒè„šæœ¬
æ•´åˆæ‰€æœ‰ç»„ä»¶ï¼Œæ‰§è¡Œå®Œæ•´çš„æ¨¡å‹è®­ç»ƒæµç¨‹
"""

import os
import sys
import time
import json
import argparse
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

try:
    import torch
    import torch.nn as nn
    from torch.utils.data import DataLoader, Dataset, random_split
    import numpy as np
    from tqdm import tqdm
    DEPENDENCIES_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸  ç¼ºå°‘ä¾èµ–: {e}")
    DEPENDENCIES_AVAILABLE = False

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from src.model_architecture import create_plant_disease_model, ModelFactory
from src.model_trainer import ModelTrainer, TrainingConfig, create_default_config
from src.model_evaluator import ModelEvaluator, create_evaluator
from src.image_preprocessing import PlantDiseasePreprocessor, PreprocessingMode
from src.dataset_manager import DatasetManager
from src.plantvillage_loader import PlantVillageLoader
from src.baidu_dataset_loader import BaiduDatasetLoader

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class PlantDiseaseDataset(Dataset):
    """æ¤ç‰©ç—…å®³æ•°æ®é›†åŒ…è£…å™¨"""
    
    def __init__(self, 
                 image_paths: List[str],
                 labels: List[int],
                 class_names: List[str],
                 preprocessor: PlantDiseasePreprocessor):
        """
        åˆå§‹åŒ–æ•°æ®é›†
        
        Args:
            image_paths: å›¾åƒè·¯å¾„åˆ—è¡¨
            labels: æ ‡ç­¾åˆ—è¡¨
            class_names: ç±»åˆ«åç§°åˆ—è¡¨
            preprocessor: å›¾åƒé¢„å¤„ç†å™¨
        """
        self.image_paths = image_paths
        self.labels = labels
        self.class_names = class_names
        self.preprocessor = preprocessor
        
        assert len(image_paths) == len(labels), "å›¾åƒæ•°é‡ä¸æ ‡ç­¾æ•°é‡ä¸åŒ¹é…"
        
    def __len__(self) -> int:
        return len(self.image_paths)
    
    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:
        """è·å–å•ä¸ªæ ·æœ¬"""
        image_path = self.image_paths[idx]
        label = self.labels[idx]
        
        try:
            # é¢„å¤„ç†å›¾åƒ
            image = self.preprocessor.preprocess_image(image_path)
            return image, label
        except Exception as e:
            logger.error(f"åŠ è½½å›¾åƒå¤±è´¥ {image_path}: {e}")
            # è¿”å›é›¶å¼ é‡ä½œä¸ºå¤‡ç”¨
            zero_image = torch.zeros(3, *self.preprocessor.input_size)
            return zero_image, label

class TrainingManager:
    """è®­ç»ƒç®¡ç†å™¨"""
    
    def __init__(self, config_path: Optional[str] = None):
        """
        åˆå§‹åŒ–è®­ç»ƒç®¡ç†å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        if not DEPENDENCIES_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£…å¿…è¦ä¾èµ–")
        
        # åŠ è½½é…ç½®
        self.config = self._load_config(config_path)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.dataset_manager = DatasetManager()
        self.trainer = None
        self.evaluator = None
        
        # æ•°æ®é›†ä¿¡æ¯
        self.train_dataset = None
        self.val_dataset = None
        self.test_dataset = None
        self.class_names = []
        
        logger.info("è®­ç»ƒç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_config(self, config_path: Optional[str]) -> TrainingConfig:
        """åŠ è½½è®­ç»ƒé…ç½®"""
        if config_path and os.path.exists(config_path):
            with open(config_path, 'r') as f:
                config_dict = json.load(f)
            
            # åˆ›å»ºé…ç½®å¯¹è±¡
            config = TrainingConfig()
            for key, value in config_dict.items():
                if hasattr(config, key):
                    setattr(config, key, value)
            
            logger.info(f"é…ç½®å·²ä»æ–‡ä»¶åŠ è½½: {config_path}")
        else:
            # ä½¿ç”¨é»˜è®¤é…ç½®
            config = create_default_config(
                num_epochs=50,
                batch_size=32,
                learning_rate=0.001,
                model_name='efficientnet-b4',
                pretrained=True,
                early_stopping=True,
                patience=10,
                save_dir='checkpoints/plant_disease_model'
            )
            logger.info("ä½¿ç”¨é»˜è®¤è®­ç»ƒé…ç½®")
        
        return config
    
    def prepare_datasets(self) -> Dict[str, Any]:
        """å‡†å¤‡è®­ç»ƒæ•°æ®é›†"""
        logger.info("å¼€å§‹å‡†å¤‡æ•°æ®é›†...")
        
        # åŠ è½½PlantVillageæ•°æ®é›†
        plantvillage_loader = PlantVillageLoader()
        plantvillage_data = plantvillage_loader.load_dataset()
        
        if not plantvillage_data['success']:
            raise RuntimeError(f"PlantVillageæ•°æ®é›†åŠ è½½å¤±è´¥: {plantvillage_data['message']}")
        
        # è·å–æ•°æ®é›†ä¿¡æ¯
        dataset_info = plantvillage_data['dataset_info']
        self.class_names = list(dataset_info['class_mapping'].values())
        
        logger.info(f"æ•°æ®é›†åŠ è½½å®Œæˆ:")
        logger.info(f"  æ€»æ ·æœ¬æ•°: {dataset_info['total_samples']:,}")
        logger.info(f"  ç±»åˆ«æ•°: {dataset_info['num_classes']}")
        logger.info(f"  å›¾åƒå°ºå¯¸èŒƒå›´: {dataset_info['image_size_stats']}")
        
        # å‡†å¤‡å›¾åƒè·¯å¾„å’Œæ ‡ç­¾
        image_paths = []
        labels = []
        
        for class_name, class_data in plantvillage_data['class_data'].items():
            class_id = list(dataset_info['class_mapping'].keys())[
                list(dataset_info['class_mapping'].values()).index(class_name)
            ]
            
            for img_path in class_data['image_paths']:
                image_paths.append(img_path)
                labels.append(class_id)
        
        # æ•°æ®é›†åˆ†å‰²
        total_size = len(image_paths)
        train_size = int(0.7 * total_size)
        val_size = int(0.15 * total_size)
        test_size = total_size - train_size - val_size
        
        # éšæœºåˆ†å‰²ï¼ˆä¿æŒç±»åˆ«å¹³è¡¡ï¼‰
        from sklearn.model_selection import train_test_split
        
        # å…ˆåˆ†å‡ºè®­ç»ƒé›†
        train_paths, temp_paths, train_labels, temp_labels = train_test_split(
            image_paths, labels, 
            test_size=(val_size + test_size),
            stratify=labels,
            random_state=42
        )
        
        # å†åˆ†å‡ºéªŒè¯é›†å’Œæµ‹è¯•é›†
        val_paths, test_paths, val_labels, test_labels = train_test_split(
            temp_paths, temp_labels,
            test_size=test_size,
            stratify=temp_labels,
            random_state=42
        )
        
        # åˆ›å»ºé¢„å¤„ç†å™¨
        train_preprocessor = PlantDiseasePreprocessor(
            input_size=(224, 224),
            mode=PreprocessingMode.TRAINING
        )
        val_preprocessor = PlantDiseasePreprocessor(
            input_size=(224, 224),
            mode=PreprocessingMode.VALIDATION
        )
        
        # åˆ›å»ºæ•°æ®é›†å¯¹è±¡
        self.train_dataset = PlantDiseaseDataset(
            train_paths, train_labels, self.class_names, train_preprocessor
        )
        self.val_dataset = PlantDiseaseDataset(
            val_paths, val_labels, self.class_names, val_preprocessor
        )
        self.test_dataset = PlantDiseaseDataset(
            test_paths, test_labels, self.class_names, val_preprocessor
        )
        
        dataset_summary = {
            'total_samples': total_size,
            'train_samples': len(train_paths),
            'val_samples': len(val_paths),
            'test_samples': len(test_paths),
            'num_classes': len(self.class_names),
            'class_names': self.class_names
        }
        
        logger.info(f"æ•°æ®é›†åˆ†å‰²å®Œæˆ:")
        logger.info(f"  è®­ç»ƒé›†: {dataset_summary['train_samples']:,} æ ·æœ¬")
        logger.info(f"  éªŒè¯é›†: {dataset_summary['val_samples']:,} æ ·æœ¬")
        logger.info(f"  æµ‹è¯•é›†: {dataset_summary['test_samples']:,} æ ·æœ¬")
        
        return dataset_summary
    
    def setup_training(self) -> Dict[str, Any]:
        """è®¾ç½®è®­ç»ƒç¯å¢ƒ"""
        logger.info("è®¾ç½®è®­ç»ƒç¯å¢ƒ...")
        
        # æ›´æ–°é…ç½®ä¸­çš„ç±»åˆ«æ•°
        self.config.num_classes = len(self.class_names)
        
        # åˆ›å»ºè®­ç»ƒå™¨
        self.trainer = ModelTrainer(self.config)
        
        # è®¾ç½®æ¨¡å‹
        model = self.trainer.setup_model()
        
        # åˆ›å»ºè¯„ä¼°å™¨
        self.evaluator = create_evaluator(
            class_names=self.class_names,
            device=str(self.trainer.device)
        )
        
        # è·å–æ¨¡å‹ä¿¡æ¯
        model_info = ModelFactory.get_model_info(model)
        
        setup_info = {
            'model_info': model_info,
            'device': str(self.trainer.device),
            'optimizer': type(self.trainer.optimizer).__name__,
            'scheduler': type(self.trainer.scheduler).__name__,
            'criterion': type(self.trainer.criterion).__name__
        }
        
        logger.info(f"è®­ç»ƒç¯å¢ƒè®¾ç½®å®Œæˆ:")
        logger.info(f"  æ¨¡å‹: {model_info['model_type']}")
        logger.info(f"  å‚æ•°æ•°é‡: {model_info['total_parameters']:,}")
        logger.info(f"  è®¾å¤‡: {setup_info['device']}")
        logger.info(f"  ä¼˜åŒ–å™¨: {setup_info['optimizer']}")
        
        return setup_info
    
    def train_model(self) -> Dict[str, Any]:
        """æ‰§è¡Œæ¨¡å‹è®­ç»ƒ"""
        logger.info("å¼€å§‹æ¨¡å‹è®­ç»ƒ...")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader = DataLoader(
            self.train_dataset,
            batch_size=self.config.batch_size,
            shuffle=True,
            num_workers=4,
            pin_memory=True
        )
        
        val_loader = DataLoader(
            self.val_dataset,
            batch_size=self.config.batch_size,
            shuffle=False,
            num_workers=4,
            pin_memory=True
        )
        
        # æ‰§è¡Œè®­ç»ƒ
        training_results = self.trainer.train(train_loader, val_loader)
        
        logger.info(f"è®­ç»ƒå®Œæˆ:")
        logger.info(f"  æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {training_results['best_val_acc']:.2f}%")
        logger.info(f"  æœ€ä½³è½®æ¬¡: {training_results['best_epoch']}")
        logger.info(f"  æ€»è®­ç»ƒæ—¶é—´: {training_results['total_time']:.2f}ç§’")
        
        return training_results
    
    def evaluate_model(self) -> Dict[str, Any]:
        """è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹"""
        logger.info("å¼€å§‹æ¨¡å‹è¯„ä¼°...")
        
        # åŠ è½½æœ€ä½³æ¨¡å‹
        best_model_path = Path(self.config.save_dir) / 'best_model.pth'
        if best_model_path.exists():
            checkpoint = self.trainer.load_checkpoint('best_model.pth')
            logger.info("å·²åŠ è½½æœ€ä½³æ¨¡å‹æƒé‡")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨
        test_loader = DataLoader(
            self.test_dataset,
            batch_size=self.config.batch_size,
            shuffle=False,
            num_workers=4
        )
        
        # è¯„ä¼°æ¨¡å‹
        metrics, predictions = self.evaluator.evaluate_model(
            self.trainer.model,
            test_loader,
            criterion=self.trainer.criterion,
            return_predictions=True
        )
        
        # è·å–ç±»åˆ«æŒ‡æ ‡
        class_metrics = self.evaluator.get_class_metrics()
        
        # ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š
        classification_report = self.evaluator.generate_classification_report()
        
        # ä¿å­˜è¯„ä¼°æŠ¥å‘Š
        self.evaluator.save_evaluation_report(
            metrics,
            save_dir=self.config.save_dir,
            model_name='plant_disease_efficientnet'
        )
        
        evaluation_results = {
            'overall_metrics': {
                'accuracy': metrics.accuracy,
                'f1_macro': metrics.f1_macro,
                'f1_weighted': metrics.f1_weighted,
                'precision_macro': metrics.precision_macro,
                'recall_macro': metrics.recall_macro,
                'auc_macro': metrics.auc_macro
            },
            'top_k_accuracy': metrics.top_k_accuracy,
            'class_metrics': [
                {
                    'class_name': cm.class_name,
                    'precision': cm.precision,
                    'recall': cm.recall,
                    'f1_score': cm.f1_score,
                    'support': cm.support
                }
                for cm in class_metrics
            ],
            'classification_report': classification_report
        }
        
        logger.info(f"æ¨¡å‹è¯„ä¼°å®Œæˆ:")
        logger.info(f"  æµ‹è¯•å‡†ç¡®ç‡: {metrics.accuracy:.4f}")
        logger.info(f"  F1åˆ†æ•°(å®): {metrics.f1_macro:.4f}")
        logger.info(f"  F1åˆ†æ•°(åŠ æƒ): {metrics.f1_weighted:.4f}")
        logger.info(f"  Top-3å‡†ç¡®ç‡: {metrics.top_k_accuracy.get(3, 0):.4f}")
        
        return evaluation_results
    
    def save_training_summary(self, 
                            dataset_summary: Dict[str, Any],
                            setup_info: Dict[str, Any],
                            training_results: Dict[str, Any],
                            evaluation_results: Dict[str, Any]):
        """ä¿å­˜è®­ç»ƒæ€»ç»“"""
        summary = {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'config': {
                'num_epochs': self.config.num_epochs,
                'batch_size': self.config.batch_size,
                'learning_rate': self.config.learning_rate,
                'model_name': self.config.model_name,
                'optimizer_type': self.config.optimizer_type,
                'scheduler_type': self.config.scheduler_type
            },
            'dataset_summary': dataset_summary,
            'setup_info': setup_info,
            'training_results': {
                'best_val_acc': training_results['best_val_acc'],
                'best_epoch': training_results['best_epoch'],
                'total_time': training_results['total_time']
            },
            'evaluation_results': evaluation_results
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        summary_path = Path(self.config.save_dir) / 'training_summary.json'
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        logger.info(f"è®­ç»ƒæ€»ç»“å·²ä¿å­˜: {summary_path}")
    
    def run_complete_training(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„è®­ç»ƒæµç¨‹"""
        logger.info("=" * 60)
        logger.info("å¼€å§‹æ¤ç‰©ç—…å®³è¯†åˆ«æ¨¡å‹è®­ç»ƒ")
        logger.info("=" * 60)
        
        start_time = time.time()
        
        try:
            # 1. å‡†å¤‡æ•°æ®é›†
            dataset_summary = self.prepare_datasets()
            
            # 2. è®¾ç½®è®­ç»ƒç¯å¢ƒ
            setup_info = self.setup_training()
            
            # 3. æ‰§è¡Œè®­ç»ƒ
            training_results = self.train_model()
            
            # 4. è¯„ä¼°æ¨¡å‹
            evaluation_results = self.evaluate_model()
            
            # 5. ä¿å­˜æ€»ç»“
            self.save_training_summary(
                dataset_summary, setup_info, 
                training_results, evaluation_results
            )
            
            total_time = time.time() - start_time
            
            logger.info("=" * 60)
            logger.info("è®­ç»ƒæµç¨‹å®Œæˆ")
            logger.info(f"æ€»è€—æ—¶: {total_time:.2f}ç§’")
            logger.info(f"æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {evaluation_results['overall_metrics']['accuracy']:.4f}")
            logger.info("=" * 60)
            
            return {
                'success': True,
                'total_time': total_time,
                'dataset_summary': dataset_summary,
                'training_results': training_results,
                'evaluation_results': evaluation_results
            }
            
        except Exception as e:
            logger.error(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            
            return {
                'success': False,
                'error': str(e),
                'total_time': time.time() - start_time
            }

def create_training_config_file(config_path: str):
    """åˆ›å»ºè®­ç»ƒé…ç½®æ–‡ä»¶"""
    config = {
        "num_epochs": 50,
        "batch_size": 32,
        "learning_rate": 0.001,
        "weight_decay": 1e-4,
        "model_type": "efficientnet",
        "model_name": "efficientnet-b4",
        "num_classes": 38,
        "pretrained": True,
        "optimizer_type": "adamw",
        "scheduler_type": "cosine",
        "early_stopping": True,
        "patience": 10,
        "min_delta": 0.001,
        "save_dir": "checkpoints/plant_disease_model",
        "mixed_precision": True,
        "gradient_clip_norm": 1.0,
        "label_smoothing": 0.1
    }
    
    with open(config_path, 'w') as f:
        json.dump(config, f, indent=2)
    
    print(f"è®­ç»ƒé…ç½®æ–‡ä»¶å·²åˆ›å»º: {config_path}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ¤ç‰©ç—…å®³è¯†åˆ«æ¨¡å‹è®­ç»ƒ')
    parser.add_argument('--config', type=str, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--create-config', type=str, help='åˆ›å»ºé…ç½®æ–‡ä»¶')
    
    args = parser.parse_args()
    
    if args.create_config:
        create_training_config_file(args.create_config)
        return
    
    # æ£€æŸ¥ä¾èµ–
    if not DEPENDENCIES_AVAILABLE:
        print("âŒ ç¼ºå°‘å¿…è¦ä¾èµ–ï¼Œè¯·è¿è¡Œ: pip install -r requirements.txt")
        return
    
    # åˆ›å»ºè®­ç»ƒç®¡ç†å™¨
    training_manager = TrainingManager(args.config)
    
    # è¿è¡Œå®Œæ•´è®­ç»ƒ
    results = training_manager.run_complete_training()
    
    if results['success']:
        print("\nğŸ‰ è®­ç»ƒæˆåŠŸå®Œæˆ!")
        print(f"ğŸ“Š æœ€ç»ˆå‡†ç¡®ç‡: {results['evaluation_results']['overall_metrics']['accuracy']:.4f}")
        print(f"â±ï¸  æ€»è€—æ—¶: {results['total_time']:.2f}ç§’")
    else:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {results['error']}")

if __name__ == "__main__":
    main()