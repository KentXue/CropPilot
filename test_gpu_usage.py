#!/usr/bin/env python3
"""
GPUä½¿ç”¨æµ‹è¯•è„šæœ¬
éªŒè¯RTX 4050æ˜¯å¦è¢«æ­£ç¡®ä½¿ç”¨è¿›è¡Œè®­ç»ƒ
"""

import torch
import torch.nn as nn
import time
import psutil
import os

def test_gpu_selection():
    """æµ‹è¯•GPUé€‰æ‹©é€»è¾‘"""
    print("ğŸ” GPUé€‰æ‹©æµ‹è¯•")
    print("=" * 50)
    
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨")
        return
    
    gpu_count = torch.cuda.device_count()
    print(f"æ£€æµ‹åˆ° {gpu_count} ä¸ªGPU:")
    
    best_gpu = 0
    for i in range(gpu_count):
        gpu_name = torch.cuda.get_device_name(i)
        print(f"  GPU {i}: {gpu_name}")
        
        # RTXã€GTXç­‰ç‹¬ç«‹æ˜¾å¡ä¼˜å…ˆ
        if any(keyword in gpu_name.upper() for keyword in ['RTX', 'GTX', 'TESLA', 'QUADRO']):
            best_gpu = i
            print(f"    âœ… é€‰æ‹©æ­¤GPUç”¨äºè®­ç»ƒ")
        else:
            print(f"    âšª é›†æˆæ˜¾å¡ï¼Œä¸ä¼˜å…ˆé€‰æ‹©")
    
    selected_device = torch.device(f'cuda:{best_gpu}')
    print(f"\nğŸ¯ æœ€ç»ˆé€‰æ‹©: {selected_device} - {torch.cuda.get_device_name(best_gpu)}")
    
    return selected_device

def test_gpu_computation(device, duration=10):
    """æµ‹è¯•GPUè®¡ç®—è´Ÿè½½"""
    print(f"\nğŸš€ GPUè®¡ç®—æµ‹è¯• (è®¾å¤‡: {device})")
    print("=" * 50)
    
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œ
    model = nn.Sequential(
        nn.Linear(1000, 2000),
        nn.ReLU(),
        nn.Linear(2000, 1000),
        nn.ReLU(),
        nn.Linear(1000, 100)
    ).to(device)
    
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    print(f"å¼€å§‹ {duration} ç§’çš„GPUè®¡ç®—æµ‹è¯•...")
    
    start_time = time.time()
    step = 0
    
    while time.time() - start_time < duration:
        # ç”Ÿæˆéšæœºæ•°æ®
        batch_size = 64
        x = torch.randn(batch_size, 1000, device=device)
        y = torch.randn(batch_size, 100, device=device)
        
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        output = model(x)
        loss = criterion(output, y)
        
        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()
        
        step += 1
        
        # æ¯100æ­¥æ˜¾ç¤ºä¸€æ¬¡çŠ¶æ€
        if step % 100 == 0:
            elapsed = time.time() - start_time
            gpu_memory = torch.cuda.memory_allocated(device) / 1024**3
            
            print(f"æ­¥éª¤ {step:4d}: æŸå¤±={loss.item():.4f}, "
                  f"æ—¶é—´={elapsed:.1f}s, æ˜¾å­˜={gpu_memory:.2f}GB")
    
    total_time = time.time() - start_time
    print(f"\nâœ… GPUè®¡ç®—æµ‹è¯•å®Œæˆ:")
    print(f"   æ€»æ­¥éª¤: {step}")
    print(f"   æ€»æ—¶é—´: {total_time:.2f}ç§’")
    print(f"   å¹³å‡æ­¥éª¤æ—¶é—´: {total_time/step*1000:.2f}ms")
    print(f"   æœ€ç»ˆæ˜¾å­˜ä½¿ç”¨: {torch.cuda.memory_allocated(device) / 1024**3:.2f}GB")

def monitor_system_resources():
    """ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨"""
    print(f"\nğŸ“Š ç³»ç»Ÿèµ„æºç›‘æ§")
    print("=" * 50)
    
    # CPUä½¿ç”¨ç‡
    cpu_percent = psutil.cpu_percent(interval=1)
    print(f"CPUä½¿ç”¨ç‡: {cpu_percent:.1f}%")
    
    # å†…å­˜ä½¿ç”¨
    memory = psutil.virtual_memory()
    print(f"å†…å­˜ä½¿ç”¨: {memory.percent:.1f}% ({memory.used/1024**3:.1f}GB / {memory.total/1024**3:.1f}GB)")
    
    # GPUä¿¡æ¯
    if torch.cuda.is_available():
        for i in range(torch.cuda.device_count()):
            gpu_name = torch.cuda.get_device_name(i)
            gpu_memory = torch.cuda.memory_allocated(i) / 1024**3
            gpu_memory_total = torch.cuda.get_device_properties(i).total_memory / 1024**3
            
            print(f"GPU {i} ({gpu_name}):")
            print(f"  æ˜¾å­˜ä½¿ç”¨: {gpu_memory:.2f}GB / {gpu_memory_total:.1f}GB")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª GPUä½¿ç”¨éªŒè¯æµ‹è¯•")
    print("=" * 80)
    
    # 1. æµ‹è¯•GPUé€‰æ‹©
    device = test_gpu_selection()
    
    # 2. ç›‘æ§ç³»ç»Ÿèµ„æº
    monitor_system_resources()
    
    # 3. æµ‹è¯•GPUè®¡ç®—
    if torch.cuda.is_available():
        test_gpu_computation(device, duration=15)
        
        # 4. å†æ¬¡ç›‘æ§èµ„æº
        print(f"\nğŸ“Š æµ‹è¯•åç³»ç»Ÿèµ„æº:")
        monitor_system_resources()
    else:
        print("âŒ æ— æ³•è¿›è¡ŒGPUè®¡ç®—æµ‹è¯•")
    
    print("\n" + "=" * 80)
    print("âœ… GPUä½¿ç”¨éªŒè¯æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    main()