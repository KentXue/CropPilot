#!/usr/bin/env python3
"""
è®­ç»ƒç®¡é“æµ‹è¯•è„šæœ¬
å¿«é€Ÿæµ‹è¯•è®­ç»ƒæµç¨‹çš„å„ä¸ªç»„ä»¶
"""

import os
import sys
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

try:
    import torch
    import torch.nn as nn
    from torch.utils.data import DataLoader, TensorDataset
    import numpy as np
    DEPENDENCIES_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸  ç¼ºå°‘ä¾èµ–: {e}")
    DEPENDENCIES_AVAILABLE = False

from src.model_architecture import create_plant_disease_model, ModelFactory
from src.model_trainer import ModelTrainer, create_default_config
from src.model_evaluator import create_evaluator
from src.image_preprocessing import PlantDiseasePreprocessor, PreprocessingMode

def create_dummy_dataset(num_samples: int = 1000, num_classes: int = 38):
    """åˆ›å»ºè™šæ‹Ÿæ•°æ®é›†ç”¨äºæµ‹è¯•"""
    print(f"åˆ›å»ºè™šæ‹Ÿæ•°æ®é›†: {num_samples} æ ·æœ¬, {num_classes} ç±»åˆ«")
    
    # åˆ›å»ºéšæœºå›¾åƒæ•°æ®
    images = torch.randn(num_samples, 3, 224, 224)
    labels = torch.randint(0, num_classes, (num_samples,))
    
    # åˆ†å‰²æ•°æ®é›†
    train_size = int(0.7 * num_samples)
    val_size = int(0.15 * num_samples)
    test_size = num_samples - train_size - val_size
    
    train_dataset = TensorDataset(images[:train_size], labels[:train_size])
    val_dataset = TensorDataset(images[train_size:train_size+val_size], labels[train_size:train_size+val_size])
    test_dataset = TensorDataset(images[train_size+val_size:], labels[train_size+val_size:])
    
    return train_dataset, val_dataset, test_dataset

def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    print("\nğŸ—ï¸ æµ‹è¯•æ¨¡å‹åˆ›å»º...")
    
    try:
        # åˆ›å»ºEfficientNetæ¨¡å‹
        model = create_plant_disease_model(
            model_type='efficientnet',
            num_classes=38,
            model_name='efficientnet-b4',
            pretrained=False  # é¿å…ä¸‹è½½é¢„è®­ç»ƒæƒé‡
        )
        
        model_info = ModelFactory.get_model_info(model)
        
        print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ:")
        print(f"   æ¨¡å‹ç±»å‹: {model_info['model_type']}")
        print(f"   å‚æ•°æ•°é‡: {model_info['total_parameters']:,}")
        print(f"   æ¨¡å‹å¤§å°: {model_info['model_size_mb']:.2f} MB")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        test_input = torch.randn(2, 3, 224, 224)
        with torch.no_grad():
            output = model(test_input)
        
        print(f"   å‰å‘ä¼ æ’­æµ‹è¯•: è¾“å…¥ {test_input.shape} -> è¾“å‡º {output.shape}")
        
        return model
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return None

def test_trainer_setup():
    """æµ‹è¯•è®­ç»ƒå™¨è®¾ç½®"""
    print("\nğŸ”§ æµ‹è¯•è®­ç»ƒå™¨è®¾ç½®...")
    
    try:
        # åˆ›å»ºè®­ç»ƒé…ç½®
        config = create_default_config(
            num_epochs=3,  # çŸ­è®­ç»ƒç”¨äºæµ‹è¯•
            batch_size=16,
            learning_rate=0.001,
            model_name='efficientnet-b4',
            pretrained=False,
            save_dir='test_checkpoints',
            mixed_precision=False  # é¿å…å¯èƒ½çš„å…¼å®¹æ€§é—®é¢˜
        )
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = ModelTrainer(config)
        
        # è®¾ç½®æ¨¡å‹
        model = trainer.setup_model()
        
        print(f"âœ… è®­ç»ƒå™¨è®¾ç½®æˆåŠŸ:")
        print(f"   è®¾å¤‡: {trainer.device}")
        print(f"   ä¼˜åŒ–å™¨: {type(trainer.optimizer).__name__}")
        print(f"   è°ƒåº¦å™¨: {type(trainer.scheduler).__name__}")
        print(f"   æŸå¤±å‡½æ•°: {type(trainer.criterion).__name__}")
        
        return trainer
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå™¨è®¾ç½®å¤±è´¥: {e}")
        return None

def test_evaluator_setup():
    """æµ‹è¯•è¯„ä¼°å™¨è®¾ç½®"""
    print("\nğŸ“Š æµ‹è¯•è¯„ä¼°å™¨è®¾ç½®...")
    
    try:
        # åˆ›å»ºç±»åˆ«åç§°
        class_names = [f'Disease_{i:02d}' for i in range(38)]
        
        # åˆ›å»ºè¯„ä¼°å™¨
        evaluator = create_evaluator(class_names=class_names)
        
        print(f"âœ… è¯„ä¼°å™¨è®¾ç½®æˆåŠŸ:")
        print(f"   è®¾å¤‡: {evaluator.device}")
        print(f"   ç±»åˆ«æ•°: {len(class_names)}")
        
        return evaluator, class_names
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°å™¨è®¾ç½®å¤±è´¥: {e}")
        return None, None

def test_preprocessing():
    """æµ‹è¯•å›¾åƒé¢„å¤„ç†"""
    print("\nğŸ–¼ï¸ æµ‹è¯•å›¾åƒé¢„å¤„ç†...")
    
    try:
        # åˆ›å»ºé¢„å¤„ç†å™¨
        train_preprocessor = PlantDiseasePreprocessor(
            input_size=(224, 224),
            mode=PreprocessingMode.TRAINING
        )
        
        val_preprocessor = PlantDiseasePreprocessor(
            input_size=(224, 224),
            mode=PreprocessingMode.VALIDATION
        )
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        test_image = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)
        
        # æµ‹è¯•é¢„å¤„ç†
        train_processed = train_preprocessor.preprocess_image(test_image)
        val_processed = val_preprocessor.preprocess_image(test_image)
        
        print(f"âœ… å›¾åƒé¢„å¤„ç†æˆåŠŸ:")
        print(f"   è®­ç»ƒæ¨¡å¼è¾“å‡º: {train_processed.shape}")
        print(f"   éªŒè¯æ¨¡å¼è¾“å‡º: {val_processed.shape}")
        print(f"   æ•°å€¼èŒƒå›´: [{train_processed.min():.3f}, {train_processed.max():.3f}]")
        
        return train_preprocessor, val_preprocessor
        
    except Exception as e:
        print(f"âŒ å›¾åƒé¢„å¤„ç†å¤±è´¥: {e}")
        return None, None

def test_mini_training():
    """æµ‹è¯•è¿·ä½ è®­ç»ƒæµç¨‹"""
    print("\nğŸš€ æµ‹è¯•è¿·ä½ è®­ç»ƒæµç¨‹...")
    
    try:
        # åˆ›å»ºè™šæ‹Ÿæ•°æ®é›†
        train_dataset, val_dataset, test_dataset = create_dummy_dataset(
            num_samples=200, num_classes=38
        )
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
        test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)
        
        # åˆ›å»ºè®­ç»ƒé…ç½®
        config = create_default_config(
            num_epochs=2,  # åªè®­ç»ƒ2è½®
            batch_size=16,
            learning_rate=0.01,
            model_name='efficientnet-b4',
            pretrained=False,
            save_dir='test_checkpoints',
            early_stopping=False,  # å…³é—­æ—©åœ
            mixed_precision=False
        )
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = ModelTrainer(config)
        model = trainer.setup_model()
        
        print(f"å¼€å§‹è¿·ä½ è®­ç»ƒ...")
        start_time = time.time()
        
        # æ‰§è¡Œè®­ç»ƒ
        training_results = trainer.train(train_loader, val_loader)
        
        training_time = time.time() - start_time
        
        print(f"âœ… è¿·ä½ è®­ç»ƒå®Œæˆ:")
        print(f"   è®­ç»ƒæ—¶é—´: {training_time:.2f}ç§’")
        print(f"   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {training_results['best_val_acc']:.2f}%")
        print(f"   æœ€ä½³è½®æ¬¡: {training_results['best_epoch']}")
        
        # æµ‹è¯•è¯„ä¼°
        class_names = [f'Disease_{i:02d}' for i in range(38)]
        evaluator = create_evaluator(class_names=class_names)
        
        metrics, _ = evaluator.evaluate_model(
            model, test_loader, return_predictions=False
        )
        
        print(f"âœ… æ¨¡å‹è¯„ä¼°å®Œæˆ:")
        print(f"   æµ‹è¯•å‡†ç¡®ç‡: {metrics.accuracy:.4f}")
        print(f"   F1åˆ†æ•°: {metrics.f1_macro:.4f}")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        import shutil
        if os.path.exists('test_checkpoints'):
            shutil.rmtree('test_checkpoints')
        
        return True
        
    except Exception as e:
        print(f"âŒ è¿·ä½ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª æ¤ç‰©ç—…å®³è¯†åˆ«è®­ç»ƒç®¡é“æµ‹è¯•")
    print("=" * 60)
    
    if not DEPENDENCIES_AVAILABLE:
        print("âŒ ç¼ºå°‘å¿…è¦ä¾èµ–ï¼Œæ— æ³•è¿è¡Œæµ‹è¯•")
        return
    
    success_count = 0
    total_tests = 5
    
    # æµ‹è¯•1: æ¨¡å‹åˆ›å»º
    if test_model_creation() is not None:
        success_count += 1
    
    # æµ‹è¯•2: è®­ç»ƒå™¨è®¾ç½®
    if test_trainer_setup() is not None:
        success_count += 1
    
    # æµ‹è¯•3: è¯„ä¼°å™¨è®¾ç½®
    evaluator, class_names = test_evaluator_setup()
    if evaluator is not None:
        success_count += 1
    
    # æµ‹è¯•4: å›¾åƒé¢„å¤„ç†
    train_prep, val_prep = test_preprocessing()
    if train_prep is not None:
        success_count += 1
    
    # æµ‹è¯•5: è¿·ä½ è®­ç»ƒ
    if test_mini_training():
        success_count += 1
    
    print("\n" + "=" * 60)
    print(f"æµ‹è¯•å®Œæˆ: {success_count}/{total_tests} é€šè¿‡")
    
    if success_count == total_tests:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è®­ç»ƒç®¡é“å‡†å¤‡å°±ç»ª")
    else:
        print(f"âš ï¸  {total_tests - success_count} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³ç»„ä»¶")
    
    print("=" * 60)

if __name__ == "__main__":
    main()